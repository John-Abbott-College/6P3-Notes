[
  {
    "objectID": "notes/developer-environment/index.html",
    "href": "notes/developer-environment/index.html",
    "title": "Developer environment setup",
    "section": "",
    "text": "Photo by Tima Miroshnichenko",
    "crumbs": [
      "Developer environment setup"
    ]
  },
  {
    "objectID": "notes/developer-environment/index.html#overview",
    "href": "notes/developer-environment/index.html#overview",
    "title": "Developer environment setup",
    "section": "1 Overview",
    "text": "1 Overview\nThroughout this semester, we will make regular use of bash, python, git, and other 3rd party command line tools such as azure-cli and gh-cli.\nNo matter what hardware you have available at home, everyone should be comfortable completing coding assignments on their personal computers and on classroom computers.\nEveryone will need the following set up:\n\non a classroom computer:\n\na Debian WSL container with all class dependencies installed using apt\n\non personal computers:\n\nIf Windows: a Debian WSL container with all class dependencies installed using apt\nIf macOS: all class dependencies installed using brew\nIf Linux: all class dependencies installed using distribution package manager\n\n\nThe sections below show how to do that, and how to verify the installation, in each case.",
    "crumbs": [
      "Developer environment setup"
    ]
  },
  {
    "objectID": "notes/developer-environment/index.html#classroom-computers-linux-wsl",
    "href": "notes/developer-environment/index.html#classroom-computers-linux-wsl",
    "title": "Developer environment setup",
    "section": "2 Classroom computers: Linux WSL",
    "text": "2 Classroom computers: Linux WSL\nIf using a Windows machine (lab computers and/or personal) for this course, you will need to set up Windows Subsystem for Linux (WSL).\n\n2.1 Ensure necessary Windows software installed\nThese programs should already be installed on your Windows machine, but in case they are not:\n\nLink for installing git on Windows\nLink for installing Windows Terminal\n\n\n2.1.1 VS Code Extensions\nIf you have not already, install VSCode.\nThen, install the following extensions:\n\nRemote Development extension pack by Microsoft\nPython language support extension\nPython formatter/linter extension (ruff)\n\n\n\n\n2.2 Install Debian WSL\n\n\nPowershell\n\n# Verify that Debian is an available OS to install\nPS &gt; wsl --list --online # Debian should be one of the results\n\n# Install Debian\nPS &gt; wsl --install -d Debian\n\nYou will be prompted to create a username and password:\n\n\nPowershell\n\n# Recommended: All lower case. Something easy to type, e.g. your first name\nEnter new UNIX username:\n# Recommended: Don't overthink this, you can always change this later\nNew password:\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you forget the password for your WSL container, you can easily reset it.\nSee the Microsoft article Set up your linux username and password.\n\nAfter this, your installation is complete.\nSee the following links for more details if needed:\n\nInstall Debian on WSL\nChoosing Debian as the Linux distribution\nTroubleshooting WSL installation\n\n\n\n2.3 Configure terminal to use WSL\nFollow the steps in Set up Windows Terminal, particularly:\n\n\n\n\n\nWe’re going to spend a lot of time in terminal environments – you might as well enjoy using it. I find it motivating to use terminals that look and feel good to use. Image source\n\n\n\nEnsure your Debian WSL instance is the default profile\n\nThen, pin Windows Terminal to your taskbar, ideally as the first app\nUse Win+1 to open Windows Terminal automatically.\n\nChoose a theme\nChoose a color scheme\n\nCustomizing a color scheme\n\nPractise searching through terminal output using Ctrl+Shift+F\nMake sure you know how to copy/paste text in Windows Terminal\n\nYou can also use Ctrl+Shift+c and Ctrl+Shift+v to copy/paste in terminals\nYou can also use Ctrl+Insert and Shift+Insert to copy paste in terminals\n\nUse Ctrl+Shift+P to open the command palette to do almost any terminal config command (very similar to VSCode).\n\nThis is very useful for learning hotkeys for the following things:\n\nmaking terminal panes\nchanging focus\n\n\n\nSee Troubleshooting Windows Terminal for more details.\n\n\n2.4 Install dependencies\n\n2.4.1 Perform system update\n\n\nbash\n\n# Update system:\nsudo apt update && sudo apt upgrade -y\n\n\n\n2.4.2 Install python\n\n\nbash\n\n# Verify python version is &gt;= 3.9:\npython3 --version\n# Ensure pip is installed:\nsudo apt install python3-pip\npip3 --version\n\n\n\n2.4.3 Set up git\nYou’ll need to do the following to set up git on both your WSL:\n\n\nbash\n\nsudo apt install git\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@domain.com\"\n\nSee Installing Git for more detail if needed.\n\n\n2.4.4 Install other needed tools\nWe’re going to need the following packages:\n\n\nbash\n\nsudo apt install man ssh wget ca-certificates rsync pass pass-extension-otp zbar-tools vim\n\nLast update to this command: February 28, 2025\n\n\n\n\n\n\nNote\n\n\n\nIf, when running sudo apt install, you have an error like this:\n\n\nbash\n\nE: Failed to fetch &lt;url&gt; 404 Not Found [IP: &lt;ip&gt;]\nE: Unable to fetch some archives, maybe run apt get update or try with --fix-missing?\n\nMake sure you update the system:\n\n\nbash\n\n# you can also run sudo apt upgrade -y, but it's not necessary all the time.\nsudo apt update\n\nThen, try the installation command again.\n\n\nI’ll keep this command updated throughout the semester as we encounter more packages we need.\n\n\n\n2.5 Backup container to OneDrive\nOnce the initial setup is complete, backups of the WSL container are easy to make.\nOnce a backup is made, it’s easy to:\n\nrecreate the exact same image on a new machine\nrestore your image in case the disk is wiped (this seems to be happening to our lab computers…)\n\n\n2.5.1 Backup command\nFirst, let’s ensure you have a folder to keep your backups.\nRecommendation: store WSL images on your college OneDrive account. That way, you can easily share your image with your personal computer, and restore your image automatically using any college computer.\n\n\nPowershell\n\nPS &gt; md -Force \"C:\\Users\\&lt;your-username&gt;\\OneDrive\\420-6P3-W25\"\n\nThen, we’ll use wsl --export to make a backup copy of your WSL container:\n\n\nPowershell\n\n# This can take around 5 minutes to finish.\nPS &gt; wsl --export Debian \"C:\\Users\\&lt;your-username\\OneDrive\\420-6P3-W25\\debian.tar\n\n\n\n2.5.2 Restore command\nOn a new machine (or on a machine with a freshly wiped hard drive…) you can --import the backup image you created:\n\n\nPowershell\n\n# This can take around 5 minutes to finish.\nPS &gt; wsl --import Debian .\\Debian \"C:\\Users\\&lt;your-username&gt;\\OneDrive\\debian.tar\"\n\n\n\n\n\n\n\nNote\n\n\n\nAfter restoring WSL, you will find that you are automatically logged in as root instead of your username.\nThe way to set a default user in a WSL container instance is to create a [user] entry in the container’s /etc/wsl.conf file:\nOpen your wsl instance and add the following entry to /etc/wsl.conf:\n\n\n/etc/wsl.conf\n\n[user]\ndefault=username\n\nExit your distro/instance, then run a wsl --terminate &lt;distroname&gt; from PowerShell.\nWhen you restart, the default user should be set to username.\nFor more detail: https://superuser.com/a/1627461",
    "crumbs": [
      "Developer environment setup"
    ]
  },
  {
    "objectID": "notes/developer-environment/index.html#personal-computers",
    "href": "notes/developer-environment/index.html#personal-computers",
    "title": "Developer environment setup",
    "section": "3 Personal computers",
    "text": "3 Personal computers\n\n3.1 Windows (WSL)\nAfter setting up WSL on a classroom computer, and backing up your WSL to OneDrive, the easiest way to set up WSL on your personal computer is to import your backup WSL image on your personal computer.\nNote that any changes made to either container, after the import, will not be automatically synchronized.\nIf you are making many customizations, you might want to keep your backup up-to-date.\n\n\n3.2 macOS / Linux\nOn a terminal on your computer, install the packages below.\nOn OS X we’ll use brew, on Linux you can use your system’s package manager:\n\n\nbash\n\n# Update system:\nbrew update && brew upgrade\n# Verify python version is &gt;= 3.9:\npython3 --version\n# Ensure pip is installed:\npython3 -m pip install --upgrade pip\n\n# Install other dependencies\nbrew install wget ca-certificates rsync pass pass-otp zbar vim\n\nLast update to this command: February 28, 2025\nAlso ensure you have installed VSCode and configured its extensions",
    "crumbs": [
      "Developer environment setup"
    ]
  },
  {
    "objectID": "notes/developer-environment/index.html#verify-environment",
    "href": "notes/developer-environment/index.html#verify-environment",
    "title": "Developer environment setup",
    "section": "4 Verify environment",
    "text": "4 Verify environment\nYour developer environment, whether on WSL, macOS, or Linux, should be able to run the following commands with the following results:\n\n\nbash\n\n# Verify python version is &gt;= 3.9 and pip is installed\npython3 --version\npip3 --version # or pip --version\n\n# Verify git config set up: ensure the output makes sense for you\ngit config user.name\ngit config user.email\n\n# For the following no specific version is required\n# but, these commands should not fail (show error message or exit error code 1)\nman -V\nssh -V\nrsync --version\npass --version\npass otp --version\nzbarimg --version\nvim --version",
    "crumbs": [
      "Developer environment setup"
    ]
  },
  {
    "objectID": "notes/bash-scripting/index.html",
    "href": "notes/bash-scripting/index.html",
    "title": "Bash scripting",
    "section": "",
    "text": "Image source: tudoubaba.net",
    "crumbs": [
      "Bash scripting"
    ]
  },
  {
    "objectID": "notes/bash-scripting/index.html#bash-theory",
    "href": "notes/bash-scripting/index.html#bash-theory",
    "title": "Bash scripting",
    "section": "1 Bash theory",
    "text": "1 Bash theory\nBash (and other shell languages) isn’t really a programming language – it is a command interpreter that’s best used for organizing the inputs and outputs of programs written in other languages. Historically this would be the C programming language. In our class, we will be writing “real” programs in Python.\nBut I digress. Despite the fact that Bash isn’t a programming language like C or Python, you can still program in it. What do you need to know to write Bash programs?\nThese notes will cover the basic programming concepts you need to know to get the most out of writing scripts in Bash.\n\n1.1 Variables\nThis section was adapted from (“Variable Substitution” n.d.)\nIn Bash, there is no concept of “types” – this is not a compiled language where different amounts of memory need to be reserved for different types of data.\nRather, all variables in Bash are simply value-placeholders. That is:\n\nThe name of a variable is a placeholder for its value, which is the data that it holds.\nReferencing/retrieving the value of a variable is called variable substitution.\n\nFor example, if variable1 is the name of a variable, then $variable1 is a reference to its value, the data it contains.\nAn equivalent syntax for variable substitution that is generally more robust is to add curly braces, as in: ${variable1}\nRunning a command such as echo $variable1 or echo ${variable1} will cause the value referenced by variable1 to be substituted and passed to the echo command.\nHere’s an example of variable assignment and substitution:\n\n\nbash\n\n# Create a variable with the name \"a\" and the value \"375\"\n$ a=375\n\n# Create a variable with the name \"hello\" and the value of the variable \"a\" (375)\n$ hello=$a\n\n# Not a variable reference, just the string \"hello\" ...\n$ echo hello\nhello\n\n# This *is* a variable substitution\n$ echo $hello\n375\n\n# This is another way to do a variable substitution\necho ${hello}\n375\n\n\n\n\n\n\n\n\nNote\n\n\n\nNo spaces are permitted on either side of = sign when initializing variables.\n\n\n1.1.1 Variable names\nWhat can you name variables? Here are the rules:\n\nVariable names must start with a letter (not a number or any other character)\nVariable names cannot contain whitespace or punctuation\n\n\n\n1.1.2 Command substitution\nWe can also assign the results of a command to a variable:\n\n\nbash\n\n# The \"%x %r %Z\" string is an example of a date format string.\n# See `man date` for examples of other date format strings\nright_now=\"$(date +\"%x %r %Z\")\"\n\nThe characters $( ) tell the shell: “substitute the results of the enclosed command”. This technique is known as command substitution.\nIn the above example script, the variable right_now gets assigned the result of calling the date command with with the argument \"%x %r %Z\" which outputs the current date and time.\nLike variable substitutions, it is a good idea to wrap command substitutions in double quotes to prevent unwanted word splitting in case the result of the expansion contains whitespace characters – see the (#Quoting) section below.\n\n\n1.1.3 Environment variables\nThis section was adapted from (“Writing Shell Scripts - Lesson 4: Variables” n.d.) and (“Export Man Page - Linux - SS64.com” n.d.)\nAny time a shell session is initialized, some variables are already set by startup files.\nTo see all the variables that are in the environment, use the printenv command:\n\n\nbash\n\n$ printenv\nSHELL=/bin/bash\n...\n\nYou can also view environment variables in a bash session using echo:\n\n\nbash\n\n$ echo $SHELL\n/bin/bash\n\nYou can create your own environment variables using the export command.\n\n\nbash\n\n$ MYDEPT=Sales\n$ echo $MYDEPT\nSales\n$ export MYDEPT\n\n# In one line:\nexport SOMEOTHERVAR=Value\n\n\n\n\n1.2 Quoting\nThis section was adapted from (“Quoting” n.d.)\nQuoting means just that, bracketing a string in quotes. This has the effect of protecting special characters in the string from reinterpretation or expansion by the shell or shell script.\n\nA character is special if it has an interpretation other than its literal meaning. For example, the asterisk * represents a wild card character in globbing and Regular Expressions.\n\n\n\nbash\n\n$ ls -l [Vv]*\n-rw-rw-r--    1 bozo  bozo       324 Apr  2 15:05 VIEWDATA.BAT\n-rw-rw-r--    1 bozo  bozo       507 May  4 14:25 vartrace.sh\n-rw-rw-r--    1 bozo  bozo       539 Apr 14 17:11 viewdata.sh\n\n$ ls -l '[Vv]*'\nls: [Vv]*: No such file or directory\n\n$ ls -l '[vv]*'\nls: [vv]*: no such file or directory\n\n\n1.2.1 Quoting variables\nWhen referencing a variable, it is generally advisable to enclose its name in double quotes, like so:\n\n\nbash\n\n$ local var=\"string-with-special-characters#*;&gt;,\"\n$ echo \"$var\"\nstring-with-special-characters#*;&gt;,\n\nThis prevents reinterpretation of all special characters within the quoted string, with the following exceptions:\n\n$ (used for variable dereferencing)\n\\ (escape character)\n\nKeeping $ as a special character within double quotes permits referencing a quoted variable ($variable), that is, replacing the variable with its value in the resulting string.\nUsing double quotes also prevents word splitting. An argument enclosed in double quotes presents itself as a single word, even if it contains whitespace separators.\n\n\nbash\n\nList=\"one two three\"\n\nfor a in $List     # Splits the variable in parts at whitespace.\ndo\n  echo \"$a\"\ndone\n# one\n# two\n# three\n\necho \"---\"\n\nfor a in \"$List\"   # Preserves whitespace in a single variable.\ndo #     ^     ^\n  echo \"$a\"\ndone\n# one two three\n\n\n\n1.2.2 Escaping\nEscaping is a method of quoting single characters. The escape \\ preceding a character tells the shell to interpret that character literally.\n\n\nbash\n\n$ echo \"Hello world\"\nHello world\n\n$ echo \"Hello \\\"world\\\"\"\nHello \"world\"\n\nYou can see more examples and information on escaping here.\n\n\n1.2.3 Single quotes\nSingle quotes ' operate similarly to double quotes, but do not permit referencing variables, since the special meaning of $ is turned off.\nWithin single quotes, every special character except ' gets interpreted literally. Consider single quotes (‘full quoting’) to be a stricter method of quoting than double quotes (“partial quoting”).\nSince even the escape character \\ gets a literal interpretation within single quotes, trying to enclose a single quote within single quotes will not yield the expected result.\n\n\n\n1.3 Functions\nThis section was adapted from (“Writing Shell Scripts - Lesson 6: Shell Functions” n.d.)\nAs programs get longer and more complex, they become more difficult to design, code, and maintain. As with any large endeavor, it is often useful to break a single, large task into a series of smaller tasks. We can do this with functions.\nA couple of important points about functions in bash:\n\nThey must be defined before they can be used.\nSecond, the function body (the portions of the function between the { and } characters) must contain at least one valid command.\n\nHere is an example:\n\n\nbash\n\n# The function definition must come before any function calls\nsystem_info()\n{\n  # At least one valid command is required in a function body\n  echo \"function system_info\"\n}\n\n# No brackets are included in the function call\nsystem_info\n\nRunning the above lines will define the system_info() function, then call it, simply result in the echo command running.\n\n1.3.1 Positional parameters\nFunctions in bash support positional parameters by default. This allows us to do things like specify the name of the output file on the command line, as well as set a default output file name if no name is specified.\nPositional parameters are a series of special variables ($0 through $9) that contain the contents of the command line.\nFor example, let’s change the earlier function definition above slightly:\n\n\nbash\n\nsystem_info()\n{\n  echo \"$1\"\n  echo \"$2\"\n  echo \"$3\"\n}\n\nThen, let’s see what happens if we were to use this function:\n\n\nbash\n\n$ system_info Hello world !\nHello\nworld\n!\n\n$ system_info \"Hello world!\" \"How are you?\" \"I am good, thanks!\"\nHello world!\nHow are you?\nI am good, thanks!\n\n\n\n1.3.2 Detecting positional parameters\nOften, we will want to check to see if we have command line arguments on which to act. There are a couple of ways to do this. First, we could simply check to see if $1 contains anything like so:\n\n\nbash\n\nif [ \"$1\" != \"\" ]; then\n    echo \"Positional parameter 1 contains something\"\nelse\n    echo \"Positional parameter 1 is empty\"\nfi\n\nSecond, the shell maintains a variable called $# that contains the number of items on the command line in addition to the name of the command ($0).\n\n\nbash\n\n# -gt means \"greater than\" in Bash, and -lt is \"less than\".\nif [ $# -gt 0 ]; then\n    echo \"Your command line contains $# arguments\"\nelse\n    echo \"Your command line contains no arguments\"\nfi\n\n\n\n1.3.3 Naming positional parameters with local\nIn a function that has many positional parameters, it can be difficult to keep track of what each $1 $2, etc. should mean.\nA common practise in bash functions is to create named variables within a function using local:\n\n\nbash\n\nsystem_info()\n{\n  local param1=\"$1\"\n  local param2=\"$2\"\n  local param3=\"$3\"\n}\n\nlocal is a bash builtin that can only be used within a function; it makes the variable name have a visible scope restricted to that function.\n\n\n\n1.4 Conditionals\nThis section was adapted from (“Writing Shell Scripts - Lesson 8: Flow Control - Part 1” n.d.)\nMost programs need to make decisions and perform different actions depending on various conditions. In bash, there are two main things to know for achieving conditional logic:\n\nHow the shell evaluates the success or failure of a command (Exit status)\nHow the shell can control the flow of execution in our program.\n\nThese two things are elaborated in the following sections.\n\n1.4.1 Exit status\nCommands (including the scripts and shell functions we write) issue a value to the system when they terminate, called an exit status. This value, which is an integer in the range of 0 to 2551, indicates the success or failure of the command’s execution. By convention, a value of zero indicates success and any other value indicates failure.\n1 Most of these numbers aren’t used – 0 (success) and 1 (failure) are most common. You can see a useful discussion of where to find more information about exit codes on stackoverflow.The shell provides a parameter $? that we can use to examine the exit status of the previously run command. Here we see it in action:\n\n\nbash\n\n$ ls -d /usr/bin\n/usr/bin\n\n# The last command terminated sucessfully, so we have a zero exit code when calling $?\n$ echo $?\n0\n\n$ ls -d /bin/usr\nls: cannot access /bin/usr: No such file or directory\n\n# The last command did not terminate successfully, so we have a non-zero exit code when calling $?\n$ echo $?\n2\n\nSome commands use different exit status values to provide diagnostics for errors, while many commands simply exit with a value of one when they fail. man pages often include a section entitled “Exit Status,” describing what codes are used. However, a zero always indicates success.\nThe shell provides two extremely simple builtin commands that do nothing except terminate with either a zero or one exit status. The true command always executes successfully and the false command always executes unsuccessfully:\n\n\nbash\n\n$ true\n$ echo $?\n0\n$ false\n$ echo $?\n1\n\nWe can use these commands to see how the if statement works. What the if statement really does is evaluate the success or failure of commands:\n\n\nbash\n\n$ if true; then echo \"It's true.\"; fi\nIt's true.\n\n$ if false; then echo \"It's true.\"; fi\n$\n\nThe command echo “It’s true.” is executed when the command following if executes successfully, and is not executed when the command following if does not execute successfully.\n\n\n1.4.2 exit\nWe can (and should!) set the exit status of our own scripts when they finish. To do this, use the exit command. The exit command causes the script to terminate immediately and set the exit status to whatever value is given as an argument.\nFor example: exit 0 exits our script and sets the exit status to 0 (success), whereas exit 1 exits your script and sets the exit status to 1 (failure).\n\n\n1.4.3 if\nThe if command is fairly simple on the surface; it makes a decision based on the exit status of a command. The if command’s syntax looks like this:\n\n\nbash\n\nif commands; then\n    commands\n[elif commands; then\n    commands...]\n[else\n    commands]\nfi\n\nTypically, you will see the if command combined with the test command, seen below.\n\n\n1.4.4 test\nThe test command is used most often with the if command to perform true/false decisions.\nThe command is unusual in that it has two different syntactic forms:\n\n\nbash\n\n# First form\ntest expression\n\n# Second form, which is far more common\n# Note: the word \"test\" does not appear, but this is in fact a \"test\" command!\n[ expression ]\n\n\n\nNotice the spaces between the [ ] braces and the expression – the whitespace is required.\nThe test command works simply. If the given expression is true, test exits with a status of zero; otherwise it exits with a status of 1.\nThe neat feature of test is the variety of expressions we can create. Here is an example:\n\n\nbash\n\nif [ -f .bash_profile ]; then\n    echo \"You have a .bash_profile. Things are fine.\"\nelse\n    echo \"Yikes! You have no .bash_profile!\"\nfi\n\nIn this example, we use the expression -f .bash_profile. This expression asks, “Is .bash_profile a file?” If the expression is true, then test exits with a zero (indicating true) and the if command executes the command(s) following the word then. If the expression is false, then test exits with a status of one and the if command executes the command(s) following the word else.\nHere is a partial list of the conditions that test can evaluate. Since test is a shell builtin, use help test to see a complete list:\n\n\n\nExpression\nDescription\n\n\n\n\n-d file\nTrue if file is a directory.\n\n\n-e file\nTrue if file exists.\n\n\n-f file\nTrue if file exists and is a regular file.\n\n\n-L file\nTrue if file is a symbolic link.\n\n\n-r file\nTrue if file is a file readable by you.\n\n\n-w file\nTrue if file is a file writable by you.\n\n\n-x file\nTrue if file is a file executable by you.\n\n\nfile1 -nt file2\nTrue if file1 is newer than file2.\n\n\nfile1 -ot file2\nTrue if file1 is older than file2.\n\n\n-z string\nTrue if string is empty.\n\n\n-n string\nTrue if string is not empty.\n\n\nstring1 = string2\nTrue if string1 equals string2.\n\n\nstring1 != string2\nTrue if string1 does not equal string2.\n\n\n\n\n\n1.4.5 A quick note on syntax\nNote that the above example can be written in a few ways:\n\n\nbash\n\n# Preferred form\nif [ -f .bash_profile ]; then\n    echo \"You have a .bash_profile. Things are fine.\"\nelse\n    echo \"Yikes! You have no .bash_profile!\"\nfi\n\n# Alternate form\nif [ -f .bash_profile ]\nthen echo \"You have a .bash_profile. Things are fine.\"\nelse echo \"Yikes! You have no .bash_profile!\"\nfi\n\nThe semicolon ; is a command separator. Using it allows us to put more than one command on a line.\nFor example: $ clear; ls will clear the screen, then execute the ls command.\nWe use the semicolon as we did to allow us to put the word then on the same line as the if command, because it’s easier to read that way.",
    "crumbs": [
      "Bash scripting"
    ]
  },
  {
    "objectID": "notes/bash-scripting/index.html#code-reuse",
    "href": "notes/bash-scripting/index.html#code-reuse",
    "title": "Bash scripting",
    "section": "2 Code reuse",
    "text": "2 Code reuse\nThe primary goal of writing a program in any language is to cryztalize useful logic in a reusable form – that is, to write a program. The outcome is that you don’t need to repeat yourself once you’ve solved a problem once.\nIn bash there are two main avenues we will take to achieve this goal:\n\ncreate function libraries\ncreate executable scripts\n\nThe following sections elaborate each technique.\n\n2.1 Function library with source\nThis section was adapted from (“Linux Command Line Adventure: Source” n.d.)\nMost programming languages permit programmers to specify external files to be included within their programs. This is often used to add “boilerplate” code to programs for such things as defining standard constants and referencing external library function definitions.\nBash has a builtin command, source, that implements this feature. This section will cover the ways it can make our scripts more powerful and easier to maintain.\nsource reads a specified file and executes the commands within it using the current shell. It works both with the interactive command line and within a script. Using the command line for example, we can reload the .bashrc file by executing the following command:\n$ source ~/.bashrc\nNote that the source command can be abbreviated by a single dot character like so:\n$ . ~/.bashrc\nWhen source is used on the command line, the commands in the file are treated as if they are being typed directly at the keyboard. In a shell script, the commands are treated as though they are part of the script.\nsource is a natural way to share functions and variables across many bash programs. For example, it makes sense to have a shared function to display error messages:\n\n\nbash\n\nerror_msg() {\n  printf \"%s\\n\" \"$1\" &gt;&2\n}\n\nTo share these functions across other scripts, we could build a library of functions and source that library. As an example, we could put all the common code in a file called ~/bash-scripts.sh and add the following code to both scripts to source that file:\n\n\nbash\n\nFUNCLIB=~/bash-scripts.sh\n\nif [[ -r \"$FUNCLIB\" ]]; then\n    source \"$FUNCLIB\"\nelse\n    echo \"Cannot read function library!\" &gt;&2\n    exit 1\nfi\n\nIf you put source statements like this in your ~/.bashrc, your functions will always be available each time you open a new terminal instance.\n\n\n2.2 Scripts\nIn the simplest terms, a shell script is a file containing a series of commands. The shell reads this file and carries out the commands as though they have been entered directly on the command line.\nSay we have the following file, example.sh:\n\n\nexample.sh\n\n#!/bin/bash\necho \"This is an example script\"\n\nWe can use the bash program to run this script:\n$ bash example.sh\nThis is an example script\nThis is fairly similar to the source command we saw earlier. The difference is a bit subtle:\n\nsource &lt;library-name&gt; will run within our current shell instance (preserving variables and functions)\nbash &lt;script-name&gt; will launch a new shell instance, which will NOT preserve variables and functions\n\nThe impetus to use one method or the other varies by purpose:\n\nwrite a library and use source to create re-useable functions to be used on the command line or in other scripts\nwrite a script to do a specific task\n\nThere is overlap between these two purposes, so don’t overthink it too much. You will often find yourself writing scripts that should be libraries, and vice versa – you can always make these changes to your programs whenever you like.\n\n2.2.1 Shebangs\nThe first line of any script, in ANY programming language (bash, sh, or, as we will soon see, `python) should start with a shebang:\n\n\nbash-script.sh\n\n#!/bin/bash\n\n# the first line beginning with #! is a shebang!\n\nLet’s break down the components of the shebang to better understand it:\n\n# – a comment\n! – in this context, a special character indicating that this line should be executed by the program that loads this file\n/bin/bash – the path to the interpreter for the code written in this file. Note that /bin/bash is an absolute path.\n\nWe will soon see that the most portable method for specifying a shebang is by providing the path to using the env program, like so:\n#!/usr/bin/env bash     # a bash script shebang\n#!/usr/bin/env sh       # a sh script shebang\n#!/usr/bin/env perl     # a perl script shebang\n#!/usr/bin/env python   # a python script shebang\nFor now, all that matters is that you provide a path to the bash program on your system. You can see valid options by running whereis bash:\n$ whereis bash\nbash: /bin/bash\n\n\n2.2.2 Permissions\nThis section was adapted from (“How-To: Set Permissions in Bash - Linux - SS64.com” n.d.)\nIn order to run a script without specifying an interpreter, you need to make the script executable, which is a permission that you can set on the file itself.\nThe sections below show how to view and set file permissions in linux filesystems.\n\n2.2.2.1 View permissions with ls\nThe ouptut of ls -l will show the current permissions for files and folders:\n-rwxr--rw- 1 user user 0 Jan 19 12:59 file1.txt\nThe letters rwx stand for Read/Write/Execute permission. These rights are shown three times, first for the Owner, then the Group and lastly Others (world)\n\n\n2.2.2.2 Edit permissions with chmod\nThe command to modify permissions is chmod. There are two ways to modify permissions, with numbers or with letters.\nCheck out this this chmod documentation for a really great interactive demo.\n\n2.2.2.2.1 Numeric\n\nchmod 400 file - Read by owner\nchmod 040 file - Read by group\nchmod 004 file - Read by world\nchmod 200 file - Write by owner\nchmod 020 file - Write by group\nchmod 002 file - Write by world\nchmod 100 file - execute by owner\nchmod 010 file - execute by group\nchmod 001 file - execute by world\n\nTo combine these, just add the numbers together:\n\nchmod 444 file - Allow read permission to owner and group and world\nchmod 777 file - Allow everyone to read, write, and execute file\n\n\n\n2.2.2.2.2 Symbolic\nchmod also accepts symbolic arguments for permission changes, where:\n\nrwx: read/write/execute\nugo: user/group/world\n\nSome examples:\n\nDeny execute permission to everyone: $ chmod a-x file\nAllow read permission to everyone: $ chmod a+r file\nMake a file readable and writable by the group and others: $ chmod go+rw file\nMake a shell script executable by the user/owner: $ chmod u+x myscript.sh\nAllow everyone to read, write, and execute the file and turn on the set group-ID: $ chmod =rwx,g+s file\n\nSome files are configured to have very restrictive permissions to prevent unauthorized access. Changing these permissions can create security problems.\nTo change or edit files that are owned by root, sudo chmod must be used. Note that changing permissions incorrectly can quickly make your system unusable! Please be careful when using sudo!\n$ sudo chmod o+x /usr/local/bin/somefile\n\n\n\n2.2.2.3 Recursive Permission Changes\nchmod -R will change all the permissions of each file and folder under a specified directory at once.\nFor example, $ chmod 777 -R /path/to/Dir will grant read/write/execute permissions to all users for ALL files in /path/to/Dir.\nTo assign reasonably secure permissions to files and folders/directories, it’s common to give files a permission of 644, and directories a 755 permission, using the find command and a pipe we can target just files or just folders as in the following examples.\n$ sudo find /path/to/Dir -type f -print0 | xargs -0 sudo chmod 644`\n$ sudo find /path/to/Dir -type d -print0 | xargs -0 sudo chmod 755\nAgain if using sudo be careful, in particular watch for extra spaces in your command/path.\n\n\n2.2.2.4 Changing Ownership and Group membership\nA file’s owner can be changed using the chown command.\n$ sudo chown kate file1.txt\nA file’s group can also be changed using the chown command.\n$ sudo chown :mygroup file1.txt\nchown can also change the owner and group in a single command:\n$ sudo chown tux:mygroup file1.txt\n\n\n\n2.2.3 Style\nYou can see the following resources for style guides for bash coding:\n\n“Unofficial Shell Scripting Stylesheet” by the Linux Documentation Project\n“Shell Style Guide” by Google developers",
    "crumbs": [
      "Bash scripting"
    ]
  },
  {
    "objectID": "notes/bash-scripting/index.html#resources",
    "href": "notes/bash-scripting/index.html#resources",
    "title": "Bash scripting",
    "section": "3 Resources",
    "text": "3 Resources\nThis section was adapted from https://linuxcommand.org/lc3_resources.php\nAside from everything covered in these notes, you can refer to the following resources:\n\nBash Builtins - commands built into the shell itself\nThe GNU Coreutils - the essential utilities included with most Linux distributions. These are divided into three groups:\n\nFile Utilities\nText Utilities\nShell Utilities\n\nOther Commands - other commonly-used Linux utilities",
    "crumbs": [
      "Bash scripting"
    ]
  },
  {
    "objectID": "notes/bash-essentials/index.html",
    "href": "notes/bash-essentials/index.html",
    "title": "Bash essentials",
    "section": "",
    "text": "Image source",
    "crumbs": [
      "Bash essentials"
    ]
  },
  {
    "objectID": "notes/bash-essentials/index.html#using-cli-effectively",
    "href": "notes/bash-essentials/index.html#using-cli-effectively",
    "title": "Bash essentials",
    "section": "1 Using CLI effectively",
    "text": "1 Using CLI effectively\nFirst things first: the terminal can feel awkward to use. What can we do about this?\nEach section below is some set of tips for using the interactive bash CLI effectively.\n\n1.1 Keyboard shortcuts\n\n\n\n\n\n\nKeyboard Shortcuts: details & examples\n\n\n\n\n\nThis section was adapted from (“Bash Keyboard Shortcuts - Linux - SS64.com” n.d.).\n\n1.1.1 Completions\nUse TAB completion for file/directory names. Type just enough characters to uniquely identify the item.\nFor example, to move to a directory sample1; Type cd sam. Then press TAB and ENTER.\n\n\n1.1.2 Moving the cursor\n\nCtrl+a: Go to the beginning of the line (Home).\nCtrl+e: Go to the End of the line (End).\nCtrl+p: Previous command (Up arrow).\nCtrl+n: Next command (Down arrow).\nAlt+b: Back (left) one word.\nAlt+f: Forward (right) one word.\nCtrl+f: Forward one character.\nCtrl+b: Backward one character.\n\n\n\n1.1.3 While using man or command --help | less\n\nk: Scroll up one line\nj: Scroll down one line\nCtrl+u: Page up\nCtrl+d: Page down\n/: Begin forward search\n?: Begin reverse search\nn/N: Find next/previous match\nq: close the less pager\n\n\n\n1.1.4 Editing\n\nCtrl+L: Clear the Screen, similar to the clear command.\nAlt+Del: Delete the Word before the cursor.\nAlt+d: Delete the Word after the cursor.\nCtrl+d: Delete character under the cursor.\nCtrl+h: Delete character before the cursor (Backspace).\nCtrl+w: Cut the Word before the cursor to the clipboard.\nCtrl+k: Cut the Line after the cursor to the clipboard.\nCtrl+u: Cut/delete the Line before the cursor to the clipboard.\nAlt+t: Swap current word with previous.\nCtrl+t: Swap the last two characters before the cursor (typo).\nctrl+y: Paste the last thing to be cut (yank).\nAlt+u: UPPER capitalize every character from the cursor to the end of the current word.\nAlt+l: Lower the case of every character from the cursor to the end of the current word.\nAlt+c: Capitalize the character under the cursor and move to the end of the word.\nAlt+r: Cancel the changes and put back the line as it was in the history (revert).\nctrl+_: Undo.\n\n\n\n1.1.5 Special keys\n\nCtrl+v tells the terminal to not interpret the following character\n\nso Ctrl+v TAB will display a tab character rather than attempting completion.\nsimilarly Ctrl+v ENTER will display the escape sequence for the Enter key: ^M\n\n\n\n\n1.1.6 History\n\nCtrl+r: Recall the last command including the specified character(s).\nCtrl+p: Previous command in history (walk back).\nCtrl+n: Next command in history (walk forward).\nCtrl+o: Execute the command found via Ctrl+r or Ctrl+s Ctrl+o\nCtrl+g: Escape from history searching mode.\n\n\n\n1.1.7 Process Control\n\nCtrl+c: Interrupt/Kill whatever you are running (SIGINT).\nCtrl+l: Clear the screen.\nCtrl+s: Stop output to the screen (for long running verbose commands). Then use PgUp/PgDn for navigation.\nCtrl+q: Allow output to the screen (if previously stopped using command above).\nCtrl+d: Send an EOF marker, unless disabled by an option, this will close the current shell (EXIT).\nCtrl+z: Send the signal SIGTSTP to the current task, which suspends it. To return to it later enter fg 'process name'\n\n\n\n\n\n\n\n1.2 Configuration\n\n\n\n\n\n\n.bashrc details & examples\n\n\n\n\n\nEvery time you open a new terminal window/tab in the bash shell, the ~/.bashrc file is read and executed.\nThe typical usecases for customising ~/.bashrc are:\n\nsetting a custom Command prompt\nsetting various useful shopts (shell options)\nsetting environment variables/aliases\nsourcing other bash files\n\nExamples of each of these are shown below.\n\n\n~/.bashrc\n\n# Set a prompt like: [username@hostname:~/CurrentWorkingDirectory]$\nexport PS1='[\\u@\\h:\\w]\\$ '\n#   Explanation:\n#   \\u: username\n#   \\h: hostname\n#   \\w: the current working directory\n#   \\$: the character $\n#   all other characters are interpreted literally\n#   See https://ss64.com/bash/syntax-prompt.html for more examples\n\n# Set useful shell options\nshopt -s autocd # auto-appends `cd` to directory, so you can cd to a path without writing `cd`\nshopt -s globstar # enables the pattern '**' for recursive file/directory wildcard matching\nshopt -s extglob # fancier pattern matching\n# See https://www.gnu.org/software/bash/manual/html_node/The-Shopt-Builtin.html for more options\n\n# Set environment variables/aliases\nexport EDITOR=\"nvim\" # neovim\nexport EDITOR=\"code\" # vscode (overwrites previous line)\n# See https://ss64.com/bash/export.html for more information\n\nalias ll=\"ls -l\" # create new alias ll for a long list\nalias cp=\"cp -iv\" # replace default cp command with interactive/verbose cp\n# See https://ss64.com/bash/alias.html for more alias info and examples\n# Note that aliases cannot handle complex logic or accept positional parameters\n# For that, we would need functions.\n\n# Source all bash files in ~/.bashrc.d/\n# This lets you define functions in various shell files in this folder and source them at startup.\nif [ -d ~/.bashrc.d ]; then\n    for rc in ~/.bashrc.d/*; do\n        if [ -f \"$rc\" ]; then\n            source \"$rc\"\n        fi\n    done\nfi\nunset rc\n# See https://ss64.com/bash/source.html for more info on sourcing\n\n\n1.2.1 Ever Wonder Why it’s Called .bashrc?\nThere are many files that end with the mysterious suffix rc like .bashrc, .vimrc, etc. Why is that? It’s a holdover from ancient Unix. Its original meaning was “run commands,” but it later became “run-control.” A run-control file is generally some kind of script or configuration file that prepares an environment for a program to use. In the case of .bashrc for example, it’s a script that prepares a user’s bash shell environment.\n\n\n\n\n\n\n\n\n\n\n.profile details & examples\n\n\n\n\n\nEvery time you log in to a linux user, the ~/.profile file is read and executed.\nThe typical usecases for customizing ~/.profile are:\n\nsetting environment variables INDEPENDENT of bash instances\n\ni.e., these variables will work in sh, zsh, and other shells\n\nsetting environment variables once per session\n\nparticularly useful for PATH, since setting it in ~/.bashrc will cause it to be updated more frequently than useful\n\n\nExamples of these are shown below:\n\n\n~/.profile\n\n# Add a directory to PATH, checking if that directory is not already in PATH first\nif ! [[ \"$PATH\" =~ \"$HOME/bin:\" ]]; then\n  export PATH=\"$PATH:$HOME/bin\"  # Adds ~/bin to your path\nfi\n\n# Source all profile files in ~/.profile.d/\n# This is useful for programs like npm, you can put its bashrc/path stuff in here instead.\nfor script in $HOME/.profile.d/*.sh ; do\n    if [ -r \"$script\" ] ; then\n        . \"$script\"\n    fi\ndone\nunset script\n# See https://ss64.com/bash/source.html for more info on sourcing\n\n\n\n\n\n\n\n\n\n\n.inputrc details & examples\n\n\n\n\n\nThis section was adapted from (“How-To: Bash Startup Files Inputrc - Linux - SS64.com” n.d.).\nThe library that is used to implement a command line interface for bash is called the Readline library.\nWhile it comes with a set of default keybindings (see the #keyboard-shortcuts section), it is possible to modify these and other behaviors of the CLI interface by putting commands into a .inputrc file, typically in the home directory.\nThe configuration options in .inputrc are particularly useful for customising the way Tab-completion works, e.g. with the ls command.\nThe inputrc variable syntax is simple:\nset variable value\nBelow are a list of variables I find particularly useful, as well as a sample .inputrc file showing how each of these are set.\n\nbell-style\nControls what happens when Readline wants to ring the terminal bell. If set to ‘none’, Readline never rings the bell. If set to ‘visible’, Readline uses a visible bell if one is available. If set to ‘audible’ (the default), Readline attempts to ring the terminal’s bell.\ncompletion-ignore-case\nIf set to ‘on’, Readline performs filename matching and completion in a case-insensitive fashion. The default value is ‘off’.\nediting-mode\nThe editing-mode variable controls which default set of key bindings is used. By default, Readline starts up in Emacs editing mode, where the keystrokes are most similar to Emacs. This variable can be set to either ‘emacs’ or ‘vi’.\nmark-symlinked-directories\nIf set to ‘on’, completed names which are symbolic links to directories have a slash appended (subject to the value of mark-directories). The default is ‘off’.\nshow-all-if-ambiguous\nThis alters the default behavior of the completion functions. If set to ‘on’, words which have more than one possible completion cause the matches to be listed immediately instead of ringing the bell. The default value is ‘off’.\n\nA sample ~/.inputrc file with these variables in use:\n\n\n~/.inputrc\n\nset bell-style none\nset completion-ignore-case On\nset editing-mode vi\nset mark-symlinked-directories On\nset show-all-if-ambiguous On\n\nYou can find many more configuration options in (“How-To: Bash Startup Files Inputrc - Linux - SS64.com” n.d.).",
    "crumbs": [
      "Bash essentials"
    ]
  },
  {
    "objectID": "notes/bash-essentials/index.html#bare-necessities",
    "href": "notes/bash-essentials/index.html#bare-necessities",
    "title": "Bash essentials",
    "section": "2 Bare necessities",
    "text": "2 Bare necessities\nThe following sections explain the purpose of each command and show a few use cases and useful options.\nThese are commands you probably already know – if you don’t, you’ll know by the end of lab-0, as you’ll need them all!\n\n2.1 Getting around: cd and ls\nNAME\n  cd - change the current directory\n  ls - list directory contents\n\nSYNOPSIS\n  cd [DIR]\n  ls [OPTION]... [FILE]...\n\n\n\n\n\n\ncd & ls details & examples\n\n\n\n\n\n\n2.1.1 cd\nUseful shorthands for cd to know:\n# Change to user home directory \n# (usually: /home/username)\n$ cd ~\n\n# WSL: Change to Windows mounted directory\n$ cd /mnt/c/\n\n# Return to previous directory\n$ cd -    # in this case, /home/username\n\n\n2.1.2 ls\nUseful ls options:\n-l                     use a long listing format\n-a, --all              do not ignore entries starting with .\n-d, --directory        list directories themselves, not their contents\n-s, --size             print the allocated size of each file, in blocks\n-t                     sort by time, newest first; see --time\n-h, --human-readable   with -l and -s, print sizes like 1K 234M 2G etc.\n    --si               likewise, but use powers of 1000 not 1024\n-R, --recursive        list subdirectories recursively\n\n\n\n\n\n\n2.2 Viewing files: cat and tac\nNAME\n  cat - concatenate files and print on the standard output\n  tac - concatenate and print files in reverse\n\nSYNOPSIS\n  cat [OPTION]... [FILE]...\n  tac [OPTION]... [FILE]...\n\n\n2.3 Creating files: touch and mkdir\nNAME\n  touch - Update the modification times of each `FILE` to the current time.\n          Creates the files if they do not exist.\n  mkdir - Create the given DIRECTORY(ies) if they do not exist\n\nSYNOPSIS\n  touch [FILE]...\n  mkdir [-p/--parents] [DIRECTORY]...\n\n\n2.4 Moving files: mv and cp\n\nNAME\n  mv - Move `SOURCE` to `DEST`, or multiple `SOURCE`(s) to `DIRECTORY`.\n  cp - Copy SOURCE to DEST, or multiple SOURCE(s) to DIRECTORY.\n\nSYNOPSIS\n  mv  [-f/--force] [-i/--interactive] [-g/--progress] [SOURCE]... [DEST]\n  cp  [-f/--force] [-i/--interactive] [-g/--progress] [-R/--recursive] [SOURCE]... [DEST]\n\n\n\n2.5 Managing permissions: chmod and chown\nNAME\n  chmod - Change the permissions mode of each FILE to MODE.\n  chown - Change file owner and group of each FILE to USER:GROUP\n\nSYNOPSIS\n  chmod [-R/--recursive] [MODE] [FILE]\n  chown [-R/--recursive] [USER:GROUP] [FILE]\n\n\n2.6 Deleting files: rm\nNAME\n  rm - Remove the FILE(s)\n\nSYNOPSIS\n  rm [-f/--force] [-i/--interactive] [-r/--recursive] [FILE]...",
    "crumbs": [
      "Bash essentials"
    ]
  },
  {
    "objectID": "notes/bash-essentials/index.html#the-five-fingers-of-death",
    "href": "notes/bash-essentials/index.html#the-five-fingers-of-death",
    "title": "Bash essentials",
    "section": "3 The five fingers of death",
    "text": "3 The five fingers of death\n\n\n\n\n\nFive Fingers of Death, or King Boxer as it is known on Wikipedia, is a martial-arts movie I have not seen, but I have heard referenced in many songs. It speaks to me that the mastery of a seemlingly small set tools (five fingers) can lead to drastic increases in capability (the ability to inflict death) and I believe this spirit applies directly to working with unix tools. Image source\n\n\nThe following 5 sets of commands are indispensable GNU Coreutils that are included on all linux systems.\nThere are many more coreutils that I have not included – I have chosen these 5 sets as I believe that mastering them, above all, will bring you in harmony with your linux system, and therefore closer to truth, happiness, and the meaning of life – or, if not, at least they will help you solve the labs that I give you in this course.\nAlmost all of these notes are adapted from a resource I found that’s pretty much exactly what I wanted to write myself: (“CLI Text Processing with GNU Coreutils” n.d.). It comes with great explanations and exercises and solutions. I may base some quizzes and tests on it!\n\n3.1 find files and grep content\nNAME\n  find - search for files that match a given expression\n  grep - print lines in file(s) that match a given pattern\n\nSYNOPSIS\n  find [STARTING-POINT...] [OPTION...] [EXPRESSION]\n  grep [OPTION...] PATTERNS [FILE...]\n\n\n\n\n\n\nfind details & examples\n\n\n\n\n\n3.1.1 find\nThis section was adapted from (“A Practical Guide to GNU Find With Examples” 2023)\nLet’s begin by looking first at find’s general syntax:\nfind [STARTING-POINT...] [OPTION...] [EXPRESSION]\nWhat are these different elements?\n\n\n\n\n\n\n\n\nElement\nDescription\nDefault\n\n\n\n\n[OPTION...]\nOptions are arguments about symlinks and search optimization.\nNone\n\n\n[STARTING-POINT...]\nList of directories to search through. The subdirectories are recursively included.\nCurrent directory\n\n\n[EXPRESSION]\nList of expressions with their (often required) values.\nNone\n\n\n\nNothing is mandatory here: running find alone will give you some output.\nHere are the different categories of [EXPRESSION]. Each of these are queries describing how to match files, or what action to perform on these files. They’re always prefixed with a single dash - (like -name for example).\n\n\n\n\n\n\n\nCategory\nDescription\n\n\n\n\nTest expressions\nMost common expressions. They’re used to filtering your files.\n\n\nAction expressions\nExpressions used to perform an action on each file found.\n\n\nOperators\nBoolean operators to manage the relationships between the different expressions.\n\n\n\nLet’s see an example that demonstrates these categories:\n\n\nbash\n\nfind . -name '*.png' -or -perm '664' -delete\n\nThis will recursively search the current directory for all files that EITHER have a filename ending with .png OR that has the permissions 664, then will delete those files. (see the course notes on permissions for more details on the meaning of 664 here.)\nLet’s see what category each of these expressions is:\n\n\n\nExpression\nCategory\n\n\n\n\n-name and -perm\nTest expressions\n\n\n-delete\nAction expression\n\n\n-or\nOperator expression\n\n\n\nThere are, of course, many different Test/Action/Operator expressions, and the beauty of the find command is combining each of these types of expressions to create stunningly efficient file search commands.\nI recommend reading/bookmarking the following resources for great explanations and examples of the various uses for the find command:\n\n“Why is using a shell loop to process text considered bad practice?” on unix.stackexchange\n“Why looping over find’s output bad practice?” on unix.stackexchange\n\n\n\n\n\n\n\n\n\n\ngrep details & examples\n\n\n\n\n\n3.1.2 grep\nThis section was adapted from (“Mastering Linux ‘Grep’ Command Guide with Practical Examples” 2024)\nThe Linux grep command is one of the most powerful and frequently used tools for text search and data filtering. Whether you’re managing system logs, searching through files, or debugging code, grep helps you find specific patterns within large sets of data quickly and efficiently.\nThe basic syntax of grep is as follows:\ngrep [OPTION...] PATTERNS [FILE...]\n\n[OPTION...]: various options you can provide grep to modify the default behavior.\nPATTERNS: the string or regular expression you want to search for.\n[FILE...]: the file(s) where you want to search.\n\n\n3.1.2.1 Practical examples\nEssentially, grep searches for a pattern and displays the matching lines. Here are a few common use-cases:\n\n3.1.2.1.1 Example 1: Searching for a Word in a File\nIf you want to search for a specific word in a file, the most basic command would be:\ngrep \"word\" filename.txt\nThis will return all lines in filename.txt that contain the word “word.”\n\n\n3.1.2.1.2 Example 2: Case-Insensitive Search\nBy default, grep is case-sensitive. If you want to ignore case distinctions, you can use the -i option:\ngrep -i \"word\" filename.txt\nThis command will return matches for both “Word” and “word” in filename.txt.\n\n\n3.1.2.1.3 Example 3: Searching Across Multiple Files\nTo search for a pattern in multiple files at once, you can use wildcards *:\ngrep \"word\" *.txt\nThis will search for “word” in all .txt files in the current directory.\n\n\n3.1.2.1.4 Example 4: Displaying Line Numbers\nTo see the line numbers where the matches occur, use the -n option:\ngrep -n \"word\" filename.txt\nThis command will display the line numbers along with the matching lines.\n\n\n3.1.2.1.5 Example 5: Recursive Search in Directories\nIf you want to search for a pattern across all files in a directory and its subdirectories, use the -r (recursive) option:\ngrep -r \"word\" /path/to/directory/\nThis will search for “word” in all files within /path/to/directory/, including subdirectories.\n\n\n3.1.2.1.6 Example 6: Inverting Search (Exclude a Pattern)\nIf you want to exclude lines that contain a specific pattern, you can use the -v option:\ngrep -v \"word\" filename.txt\nThis command will return all lines that do not contain “word”.\n\n\n3.1.2.1.7 Example 7: Counting Matches\nTo count how many times a pattern appears in a file, use the -c option:\ngrep -c \"word\" filename.txt\nThis will output the number of lines that contain “word” in filename.txt.\n\n\n\n\n\n\n\n3.2 tr characters and cut fields\nNAME\n  tr - Translate characters matching STRING1 in stdin/FILE to STRING2,\n       writing to stdout\n  cut - Prints specified columns from each line of stdin, writes to stdout\n\nSYNOPSIS\n  tr [OPTION]... STRING1 STRING2\n  cut [-d/--delimiter] [-f/--fields] [FILE]\n\n\n\n\n\n\ntr details & examples\n\n\n\n\n\n3.2.1 tr\nThe following section was adapted from (“CLI Text Processing with GNU Coreutils” n.d.)\ntr helps you to map one set of characters to another set of characters. Features like range, repeats, character sets, squeeze, complement, etc makes it a must know text processing tool.\nHere are some examples that map one set of characters to another. As a good practice, always enclose the sets in single quotes to avoid issues due to shell metacharacters.\n\n\nbash\n\n# 'l' maps to '1', 'e' to '3', 't' to '7' and 's' to '5'\n$ echo 'leet speak' | tr 'lets' '1375'\n1337 5p3ak\n\n# example with shell metacharacters\n$ echo 'apple;banana;cherry' | tr\n:\ntr: missing operand\nTry 'tr --help' for more information.\n$ echo 'apple;banana;cherry' | tr ';' ':'\napple:banana:cherry\n\n\n3.2.1.1 Character ranges\nYou can use - between two characters to construct a range (ascending order only).\n\n\nbash\n\n# uppercase to lowercase\n$ echo 'HELLO WORLD' | tr 'A-Z' 'a-z'\nhello world\n\n# swap case\n$ echo 'Hello World' | tr 'a-zA-Z' 'A-Za-z'\nhELLO wORLD\n\n# rot13\n$ echo 'Hello World' | tr 'a-zA-Z' 'n-za-mN-ZA-M'\nUryyb Jbeyq\n$ echo 'Uryyb Jbeyq' | tr 'a-zA-Z' 'n-za-mN-ZA-M'\nHello World\n\n\n\n3.2.1.2 Deleting characters\nUse the -d option to specify a set of characters to be deleted.\n$ echo ‘2024-08-12’ | tr -d ‘-’\n\n\nbash\n\n20240812\n\n# delete all punctuation characters\n$ s='\"Hi\", there! How *are* you? All fine here.'\n$ echo \"$s\" | tr -d '[:punct:]'\nHi there How are you All fine here\n\n\n\n3.2.1.3 Squeezing characters\nThe -s option changes consecutive repeated characters to a single copy of that character.\n\n\nbash\n\n$ echo 'HELLO... hhoowwww aaaaaareeeeee yyouuuu!!' | tr -s 'a-z'\nHELLO... how are you!!\n\n# translate and squeeze\n$ echo 'hhoowwww aaaaaareeeeee yyouuuu!!' | tr -s 'a-z' 'A-Z'\nHOW ARE YOU!!\n\n# delete and squeeze\n$ echo 'hhoowwww aaaaaareeeeee yyouuuu!!' | tr -sd '!' 'a-z'\nhow are you\n\n# squeeze other than lowercase alphabets\n$ echo 'apple    noon     banana!!!!!' | tr -cs 'a-z'\napple noon banana!\n\nYou can see more examples and explanations here: (“CLI Text Processing with GNU Coreutils” n.d.).\n\n\n\n\n\n\n\n\n\n\ncut details & examples\n\n\n\n\n\n3.2.2 cut\nThe following section was adapted from (“CLI Text Processing with GNU Coreutils” n.d.)\nBy default, cut splits the input content into fields based on the tab (\\t) character. You can use the -f option to select a desired field from each input line. To extract multiple fields, specify the selections separated by the comma character.\n\n\nbash\n\n# only the second field\n$ printf 'apple\\tbanana\\tcherry\\n' | cut -f2\nbanana\n\n# first and third fields\n$ printf 'apple\\tbanana\\tcherry\\n' | cut -f1,3\napple cherry\n\n\n3.2.2.1 Field ranges\nYou can use the - character to specify field ranges. You can skip the starting or ending range, but not both.\n\n\nbash\n\n# 2nd, 3rd and 4th fields\n$ printf 'apple\\tbanana\\tcherry\\tfig\\tmango\\n' | cut -f2-4\nbanana cherry fig\n\n# all fields from the start till the 3rd field\n$ printf 'apple\\tbanana\\tcherry\\tfig\\tmango\\n' | cut -f-3\napple banana cherry\n\n# all fields from the 3rd one till the end\n$ printf 'apple\\tbanana\\tcherry\\tfig\\tmango\\n' | cut -f3-\ncherry fig mango\n\n\n\n3.2.2.2 Input Delimiter\nUse the -d option to change the input delimiter. Only a single byte character is allowed. By default, the output delimiter will be same as the input delimiter.\n\n\nbash\n\n$ cat scores.csv\nName,Maths,Physics,Chemistry\nIth,100,100,100\nCy,97,98,95\nLin,78,83,80\n\n$ cut -d, -f2,4 scores.csv\nMaths,Chemistry\n100,100\n97,95\n78,80\n\n# use quotes if the delimiter is a shell metacharacter\n$ echo 'one;two;three;four' | cut -d -f3\ncut: option requires an argument -- 'd'\nTry 'cut --help' for more information.\n-f3: command not found\n$ echo 'one;two;three;four' | cut -d';' -f3\nthree\n\n\n\n3.2.2.3 Output Delimiter\nUse the --output-delimiter option to customize the output separator to any string of your choice. The string is treated literally. Depending on your shell you can use ANSI-C quoting to allow escape sequences.\n\n\nbash\n\n$ printf 'apple\\tbanana\\tcherry\\n' | cut --output-delimiter=, -f1-\napple,banana,cherry\n\n# example for multicharacter output separator\n$ echo 'one;two;three;four' | cut -d';' --output-delimiter=' : ' -f1,3-\none : three : four\n\n# ANSI-C quoting example\n# depending on your environment, you can also press Ctrl+v and then the Tab key\n$ echo 'one;two;three;four' | cut -d';' --output-delimiter=$'\\t' -f1,3-\none three four\n\n# newline as the output field separator\n$ echo 'one;two;three;four' | cut -d';' --output-delimiter=$'\\n' -f2,4\ntwo\nfour\n\nYou can see more examples and explanations here: (“CLI Text Processing with GNU Coreutils” n.d.).\n\n\n\n\n\n\n3.3 sort data and uniq duplicates\nNAME\n  sort - Display sorted concatenation of all FILE(s).\n         With no FILE, or when FILE is -, read stdin\n  uniq - Report or omit repeated lines.\n\nSYNOPSIS\n  sort [FILE]...\n  uniq [-d/--repeated] [FILE]...\n\n\n\n\n\n\nsort details & examples\n\n\n\n\n\n3.3.1 sort\nThe following section was adapted from (“CLI Text Processing with GNU Coreutils” n.d.)\nThe sort command provides a wide variety of features. In addition to lexicographic ordering, it supports various numerical formats. You can also sort based on particular columns. And there are nifty features like merging already sorted input, debugging, determining whether the input is already sorted and so on.\nBy default, sort orders the input in ascending order:\n\n\nbash\n\n$ cat greeting.txt\nHi there\nHave a nice day\n\n# extract and sort space separated words\n$ &lt;greeting.txt tr ' ' '\\n' | sort\na\nday\nHave\nHi\nnice\nthere\n\n\n3.3.1.1 Dictionary sort\nThe -d option will consider only alphabets, numbers and blanks for sorting. Space and tab characters are considered as blanks, but this would also depend on the locale.\n\n\nbash\n\n$ printf '(banana)\\n{cherry}\\n[apple]' | LC_ALL=C sort -d\n[apple]\n(banana)\n{cherry}\n\n\n\n3.3.1.2 Reversed order\nThe -r option will reverse the output order. Note that this doesn’t change how sort performs comparisons, only the output is reversed. You’ll see an example later where this distinction becomes clearer.\n\n\nbash\n\n$ printf 'peace\\nrest\\nquiet' | sort -r\nrest\nquiet\npeace\n\n\n\n3.3.1.3 Numeric sort\nThe sort command provides various options to work with numeric formats. For most cases, the -n option is enough. Here’s an example:\n\n\nbash\n\n# lexicographic ordering isn't suited for numbers\n$ printf '20\\n2\\n3\\n111\\n314' | sort\n111\n2\n20\n3\n314\n\n# -n helps in this case\n$ printf '20\\n2\\n3\\n111\\n314' | sort -n\n2\n3\n20\n111\n314\n\n\n\n\n\n\n\n\n\n\n\nuniq details & examples\n\n\n\n\n\n3.3.2 uniq\nThe following section was adapted from (“CLI Text Processing with GNU Coreutils” n.d.)\nThe uniq command identifies similar lines that are adjacent to each other. There are various options to help you filter unique or duplicate lines, count them, group them, etc.\n\n3.3.2.1 Retain single copy of duplicates\nThis is the default behavior of the uniq command. If adjacent lines are the same, only the first copy will be displayed in the output.\n\n\nbash\n\n# only the adjacent lines are compared to determine duplicates\n# which is why you get 'red' twice in the output for this input\n$ printf 'red\\nred\\nred\\ngreen\\nred\\nblue\\nblue' | uniq\nred\ngreen\nred\nblue\n\nYou’ll need sorted input to make sure all the input lines are considered to determine duplicates. For some cases, sort -u is enough, like the example shown below:\n\n\nbash\n\n# same as sort -u for this case\n$ printf 'red\\nred\\nred\\ngreen\\nred\\nblue\\nblue' | sort | uniq\nblue\ngreen\nred\n\nSometimes though, you may need to sort based on some specific criteria and then identify duplicates based on the entire line contents. Here’s an example:\n\n\nbash\n\n# can't use sort -n -u here\n$ printf '2 balls\\n13 pens\\n2 pins\\n13 pens\\n' | sort -n | uniq\n2 balls\n2 pins\n13 pens\n\n\n\n3.3.2.2 Duplicates only\nThe -d option will display only the duplicate entries. That is, only if a line is seen more than once.\n\n\nbash\n\n$ cat purchases.txt\ncoffee\ntea\nwashing powder\ncoffee\ntoothpaste\ntea\nsoap\ntea\n\n$ sort purchases.txt | uniq -d\ncoffee\ntea\n\nTo display all the copies of duplicates, use the -D option.\n\n\nbash\n\n$ sort purchases.txt | uniq -D\ncoffee\ncoffee\ntea\ntea\ntea\n\n\n\n3.3.2.3 Unique only\nThe -u option will display only the unique entries. That is, only if a line doesn’t occur more than once.\n\n\nbash\n\n$ sort purchases.txt | uniq -u\nsoap\ntoothpaste\nwashing powder\n\n# reminder that uniq works based on adjacent lines only\n$ printf 'red\\nred\\nred\\ngreen\\nred\\nblue\\nblue' | uniq -u\ngreen\nred\n\nYou can see more examples and explanations here: (“CLI Text Processing with GNU Coreutils” n.d.).\n\n\n\n\n\n\n3.4 know head from tail\nNAME\n  head - Print the first 10 lines of each `FILE` to standard output.\n         With no `FILE`, or when `FILE` is `-`, read stdin\n  tail - Print the last 10 lines of each `FILE` to standard output.\n         With no `FILE`, or when `FILE` is `-`, read stdin\n\nSYNOPSIS\n  head [-n/--lines] [FILE]...\n  tail [-n/--lines] [-f/--follow] [FILE]...\n\n\n\n\n\n\nhead & tail details & examples\n\n\n\n\n\n3.4.1 head and tail\nThe following section was adapted from (“CLI Text Processing with GNU Coreutils” n.d.)\nhead and tail, or a combination of both, are used to extract text content that you know is at the beginning, end, or specific line number of a file.\n\n3.4.1.1 Leading and trailing lines\nConsider this sample file, with line numbers prefixed for convenience.\n\n\nbash\n\n$ cat sample.txt\n 1) Hello World\n 2) \n 3) Hi there\n 4) How are you\n 5) \n 6) Just do-it\n 7) Believe it\n 8) \n 9) banana\n10) papaya\n11) mango\n12) \n13) Much ado about nothing\n14) He he he\n15) Adios amigo\n\nBy default, head and tail will display the first and last 10 lines respectively.\n\n\nbash\n\n$ head sample.txt\n 1) Hello World\n 2) \n 3) Hi there\n 4) How are you\n 5) \n 6) Just do-it\n 7) Believe it\n 8) \n 9) banana\n10) papaya\n\n$ tail sample.txt\n 6) Just do-it\n 7) Believe it\n 8) \n 9) banana\n10) papaya\n11) mango\n12) \n13) Much ado about nothing\n14) He he he\n15) Adios amigo\n\nNote: If there are less than 10 lines in the input, only those lines will be displayed.\nYou can use the -nN option to customize the number of lines:\n\n\nbash\n\n# first three lines\n# space between -n and N is optional\n$ head -n3 sample.txt\n 1) Hello World\n 2) \n 3) Hi there\n\n# last two lines\n$ tail -n2 sample.txt\n14) He he he\n15) Adios amigo\n\n\n\n3.4.1.2 Excluding N lines\nBy using a “subtraction” style syntax, like head -n -N, you can invert the selection – that is, get all the input lines EXCEPT the last -N lines in the case of head, or the first -N lines in the case of tail.\n\n\nbash\n\n# except the last 11 lines\n$ head -n -11 sample.txt\n 1) Hello World\n 2) \n 3) Hi there\n 4) How are you\n\n# except the first 11 lines\n$ tail -n -11 sample.txt\n12) \n13) Much ado about nothing\n14) He he he\n15) Adios amigo\n\nYou can see more examples and explanation at (“CLI Text Processing with GNU Coreutils” n.d.).\n\n\n\n\n\n\n3.5 tree and tee\nNAME\n  tree - list contents of DIRECTORIES in a tree-like format.\n  tee - Copy standard input to each FILE, and also to standard output.\n\nSYNOPSIS\n  tree [-L level] [DIRECTORY]...\n  tee [FILE]...\n\n\n\n\n\n\ntree & tee details & examples\n\n\n\n\n\nThere’s nothing here yet… stay tuned!",
    "crumbs": [
      "Bash essentials"
    ]
  },
  {
    "objectID": "notes/bash-essentials/index.html#redirection-and-pipes",
    "href": "notes/bash-essentials/index.html#redirection-and-pipes",
    "title": "Bash essentials",
    "section": "4 Redirection and Pipes",
    "text": "4 Redirection and Pipes\nThis section was adapted from (“How-To: Redirection and Process Substitution - Linux - SS64.com” n.d.)\nWhen Bash starts, normally, 3 file descriptors are opened, 0, 1 and 2 also known as standard input (stdin), standard output (stdout) and standard error (stderr).\nYou can use the &gt; operator to “redirect” the output of commands (which normally goes to stdout) to different files or other file descriptors. Some common examples are shown below:\ncommand  &gt;  filename     Redirect command output (stdout) into a file\ncommand  &gt;  /dev/null    Discard stdout of command\ncommand  2&gt; /dev/null    Discard stderr of command\n\ncommand  &gt;&2             Redirect command output (stdout) to stderr\n\ncommand  &gt;&gt; filename     Redirect command output and APPEND into a file\ncommand  &lt;  filename     Redirect a file into a command\n\ncommandA | commandB       Pipe stdout of commandA to commandB\ncommandA | tee filename   Pipe stdout of commandA into filename AND stdout\n\n\n\n\n\n\nRedirection explained further\n\n\n\n\n\nThis section was adapted from (“Illustrated Redirection Tutorial [Bash Hackers Wiki]” 2023)\n\n4.1 Output Redirection n&gt; file\n&gt; is probably the simplest redirection.\necho foo &gt; file\nthe &gt; file after the command alters the file descriptors belonging to the command echo. It changes the file descriptor 1 (&gt; file is the same as 1&gt;file) so that it points to the file file. They will look like:\n                  ---       +-----------------------+\nstandard input   ( 0 ) ----&gt;| /dev/pts/5            |\n                  ---       +-----------------------+\n\n                  ---       +-----------------------+\nstandard output  ( 1 ) ----&gt;| file                  |\n                  ---       +-----------------------+\n\n                  ---       +-----------------------+\nstandard error   ( 2 ) ----&gt;| /dev/pts/5            |\n                  ---       +-----------------------+\nNow characters written by our command, echo, that are sent to the standard output, i.e., the file descriptor 1, end up in the file named file.\nIn the same way, command 2&gt; file will change the standard error and will make it point to file. For example, command 2&gt; /dev/null will delete all errors outputted by command:\n                  ---       +-----------------------+\nstandard input   ( 0 ) ----&gt;| /dev/pts/5            |\n                  ---       +-----------------------+\n\n                  ---       +-----------------------+\nstandard output  ( 1 ) ----&gt;| /dev/pts/5            |\n                  ---       +-----------------------+\n\n                  ---       +-----------------------+\nstandard error   ( 2 ) ----&gt;| /dev/null             |\n                  ---       +-----------------------+\n\n\n4.2 Input Redirection n&lt; file\nWhen you run a command using command &lt; file, it changes the file descriptor 0 so that it looks like:\n                  ---       +-----------------------+\nstandard input   ( 0 ) &lt;----| file                  |\n                  ---       +-----------------------+\n\n                  ---       +-----------------------+\nstandard output  ( 1 ) ----&gt;| /dev/pts/5            |\n                  ---       +-----------------------+\n\n                  ---       +-----------------------+\nstandard error   ( 2 ) ----&gt;| /dev/pts/5            |\n                  ---       +-----------------------+\nIf the command reads from stdin, it now will read from file and not from the console.\n\n\n4.3 Pipes |\nWhat does this | do? Among other things, it connects the standard output of the command on the left to the standard input of the command on the right. That is, it creates a special file, a pipe, which is opened as a write destination for the left command, and as a read source for the right command.\ncommand:   echo foo               |                cat\n\n ---       +--------------+               ---       +--------------+\n( 0 ) ----&gt;| /dev/pts/5   |     ------&gt;  ( 0 ) ----&gt;|pipe (read)   |\n ---       +--------------+    /          ---       +--------------+\n                              /\n ---       +--------------+  /            ---       +--------------+\n( 1 ) ----&gt;| pipe (write) | /            ( 1 ) ----&gt;| /dev/pts     |\n ---       +--------------+               ---       +--------------+\n\n ---       +--------------+               ---       +--------------+\n( 2 ) ----&gt;| /dev/pts/5   |              ( 2 ) ----&gt;| /dev/pts/    |\n ---       +--------------+               ---       +--------------+\nThis is possible because the redirections are set up by the shell before the commands are executed, and the commands inherit the file descriptors.",
    "crumbs": [
      "Bash essentials"
    ]
  },
  {
    "objectID": "notes/bash-essentials/index.html#core-utilities",
    "href": "notes/bash-essentials/index.html#core-utilities",
    "title": "Bash essentials",
    "section": "5 Core utilities",
    "text": "5 Core utilities\n\n5.1 ssh\nNAME\n  ssh - OpenSSH remote login client\n\nSYNOPSIS\n  ssh [-l login_name] [-p port] DESTINATION [command [argument...]\nssh is a program for logging into a remote machine and for executing commands on a remote machine. It is intended to provide secure encrypted communications between two untrusted hosts over an insecure network.\nssh connects and logs into the specified destination, which may be specified as either [user@]hostname or a URI of the form ssh://[user@]hostname[:port].\nIf a command is specified, it will be executed on the remote host instead of a login shell.\n\n\n\n\n\n\nssh details & examples\n\n\n\n\n\n\nThere’s nothing here yet… stay tuned!\n\n\n\n\n\n5.2 rsync\nNAME\n  rsync - a fast, versatile, remote (and local) file-copying tool\n\nSYNOPSIS\n  Local:\n    rsync [OPTION...] SRC... [DEST]\n  Access via remote shell:\n    Pull:\n        rsync [OPTION...] [USER@]HOST:SRC... [DEST]\n    Push:\n        rsync [OPTION...] SRC... [USER@]HOST:DEST\nRsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon.\nIt is famous for sending only the differences between the source files and the existing files in the destination, increasing efficiency for repetitive synchronization between source and destination.\nRsync is widely used for backups and mirroring, and as an improved cp command for everyday use.\n\n\n\n\n\n\nrsync details & examples\n\n\n\n\n\n\nThere’s nothing here yet… stay tuned!\n\n\n\n\n\n5.3 tar, zip, and unzip\nNAME\n  tar - a general archiving utility for creation/extraction/compression and more\n  zip - package and compress files into a ZIP archive\n  unzip - list, test and extract compressed files from a ZIP archive\n\nSYNOPSIS\n  tar --create/--extract [--file ARCHIVE] [OPTIONS] [FILE...]\n  zip [OPTIONS] [ARCHIVE] [FILE...]\n  unzip [ARCHIVE] [-d OUTPUTDIR]\nThe tar, zip, and unzip programs provide the ability to create, extract, and otherwise manipulate archives of files, where an archive of files is simply a file that stores a collection of other files.\n\n\n\n\n\n\ntar, zip, and unzip details & examples\n\n\n\n\n\nThis section was adapted from (“GNU Tar 1.35: 2 Tutorial Introduction to Tar” n.d.).\nThe specific usecases for tar/zip/unzip are similar but vary slightly.\nAll three tools are used for efficient storage, transfer, and backup of collections of files, particularly large files via compression.\n\ntar:\n\ndefault: create/extract an uncompressed archive (.tar) of a collection of files\nwith --gzip/-z: create/extract a compressed archive (.tar.gz) of a collection of files\nwith --bzip2/-j: create/extract a compressed archive (.tar.bz2) of a collection of files\n\nzip:\n\ncreate a compressed collection of files (.zip)\n\nunzip:\n\nextract a compressed collection of files (.zip)\n\n\n\n5.3.1 Operations\nThere are two main operations of interest for archiving programs:\n\ncreate: create a new archive (.zip, .tar, .tar.gz, tar.bz2)\nextract: extract the files of an archive to a directory\n\nExamples of each follow below:\n\nCreateExtract\n\n\n# Assume you have a directory called music/ and three folders inside it:\n$ tree music\nmusic/\n├── blues\n│   └── nina-simone\n├── folk\n│   └── phil-ochs\n└── jazz\n    └── charles-mingus\n\n# Create an uncompressed archive (.tar) of all three files\n$ tar --create --file=collection.tar music\n\n# Creates a compressed archive (.zip, .tar.gz, .tar.bz2)\n$ zip -r collection.zip music\n$ tar --create --gzip --file=collection.tar.gz music\n$ tar --create --bzip2 --file=collection.tar.bz2 music\n\n# tar has shorthand versions of the above parameters\n$ tar -c -f collection.tar music\n$ tar -c -z -f collection.tar.gz music\n$ tar -cjf collection.tar.bz2 music\n\n\n\n# Assume you have the archives from the Create example:\n$ tar --list collection.tar\nmusic/\n├── blues\n│   └── nina-simone\n├── folk\n│   └── phil-ochs\n└── jazz\n    └── charles-mingus\n\n# Extract all files from an uncompressed archive (.tar) to the current directory\n$ tar --extract --file=collection.tar\n\n# Extract all files from a compressed archive (.zip, .tar.gz, .tar.bz2) to the current directory\n$ unzip collection.zip\n$ tar --extract --gzip --file=collection.tar.gz\n$ tar --extract --bzip2 --file=collection.tar.bz2\n\n# Extract all files from a compressed archive, specifying a different output directory\n$ unzip collection.zip -d ~/some-folder\n$ tar --extract --gzip --file=collection.tar.gz --directory ~/music\n$ tar --extract --bzip2 --file=collection.tar.bz2 --directory /tmp/music\n\n# tar has shorthand versions of the above parameters\n$ tar -x -f collection.tar\n$ tar -x -z -f collection.tar.gz -C ~/music\n$ tar -xjf collection.tar.bz2 -C /tmp/music\n\n\n\nEach of these operations is mutually exclusive, which makes some sense. You cannot create and extract an archive at the same time, that doesn’t make sense!\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen using --create or -c, tar will overwrite current contents of the file named by -f. To add files to an existing archive, you need to use --append or -r.\n\nYou can read more:\n\nthe usecases and history of tar at (gnu.org)\nA helpful comparison between tar and zip (stackoverflow)\nA reallyy thorough breakdown of compression in tar and zip (stackoverflow)\n\n\n\n5.4 git\nNAME\n  git - the stupid content tracker\n\nSYNOPSIS\n  git &lt;command&gt; [&lt;args&gt;]\nGit is a fast, scalable, distributed revision control system with an unusually rich command set that provides both high-level operations and full access to internals.\nSee man 7 gittutorial to get started, then see man 7 giteveryday for a useful minimum set of commands.\n\n\n\n\n\n\ngit details & examples\n\n\n\n\n\n\nThere’s nothing here yet… stay tuned!",
    "crumbs": [
      "Bash essentials"
    ]
  },
  {
    "objectID": "notes/bash-essentials/index.html#more-resources",
    "href": "notes/bash-essentials/index.html#more-resources",
    "title": "Bash essentials",
    "section": "6 More resources",
    "text": "6 More resources\n\nLinuxCommand.org\n\nShort guides on learning bash shell and bash scripting.\nLinks to interactive learning games under “Adventures”. Basic Shell Features\nComplete reference with examples.",
    "crumbs": [
      "Bash essentials"
    ]
  },
  {
    "objectID": "about/syllabus/index.html",
    "href": "about/syllabus/index.html",
    "title": "Syllabus",
    "section": "",
    "text": "Room, times, etc.: see Course Outline\nOffice: Penfield 311\nOffice hours: Mon/Fri 11:00 - 12:30pm or so\nEmail: michael DOT haaf AT johnabbott DOT qc DOT ca\nCourse webpage: This website for all content, Moodle for assignment/project/quiz submissions.\n\n\n\n\n\n\nForgive me the smarmy comic, this is usually true…\n\n\n\n\n\nTeams - For communicating (fastest, most reliable that I will check it same-day)\nMIO - For communicating (non-time-critical)\nEmail - For communicating (time-critical). Will aim for &lt;24hr response.\nMoodle - For receiving & submitting exercises/assignments/project and getting marks\n\n\n\n\n\n45% Assignments and Labs\n20% Test (first week of April)\n35% Project Milestones"
  },
  {
    "objectID": "about/syllabus/index.html#logistics",
    "href": "about/syllabus/index.html#logistics",
    "title": "Syllabus",
    "section": "",
    "text": "Room, times, etc.: see Course Outline\nOffice: Penfield 311\nOffice hours: Mon/Fri 11:00 - 12:30pm or so\nEmail: michael DOT haaf AT johnabbott DOT qc DOT ca\nCourse webpage: This website for all content, Moodle for assignment/project/quiz submissions.\n\n\n\n\n\n\nForgive me the smarmy comic, this is usually true…\n\n\n\n\n\nTeams - For communicating (fastest, most reliable that I will check it same-day)\nMIO - For communicating (non-time-critical)\nEmail - For communicating (time-critical). Will aim for &lt;24hr response.\nMoodle - For receiving & submitting exercises/assignments/project and getting marks\n\n\n\n\n\n45% Assignments and Labs\n20% Test (first week of April)\n35% Project Milestones"
  },
  {
    "objectID": "about/syllabus/index.html#course-material",
    "href": "about/syllabus/index.html#course-material",
    "title": "Syllabus",
    "section": "2 Course material",
    "text": "2 Course material\nThere are no required textbooks for this course – this website will contain all of the content that you need to complete course deliverables. Additionally, each lecture will contain references to additional resources for exploring each topic in further detail beyond the scope of the course."
  },
  {
    "objectID": "about/this-site/index.html",
    "href": "about/this-site/index.html",
    "title": "About this website",
    "section": "",
    "text": "Course content, both for lectures and assignments, has been adapted by me from a variety of sources. This section serves the purpose of both acknowledging these references as well as pointing the way for curious students to begin investigating further into course material than we had time to cover.\n\n\nAll course content was either written by Mauricio Buschinelli, Michael Haaf, or explicitly adapted from external resources with attributions made clear. This course content retains the licenses of the original works where relevant, and is otherwise licensed under the Creative Commons Attribution 4.0 International License.\n\nTerms of use\nYou are free to:\n\nShare: copy and redistribute the material in any medium or format\nAdapt: remix, transform, and build upon the material for any purpose, even commercially.\n\nUnder the following terms:\n\nAttribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n\nCreative Commons Attribution 4.0 International License"
  },
  {
    "objectID": "about/this-site/index.html#course-content",
    "href": "about/this-site/index.html#course-content",
    "title": "About this website",
    "section": "",
    "text": "Course content, both for lectures and assignments, has been adapted by me from a variety of sources. This section serves the purpose of both acknowledging these references as well as pointing the way for curious students to begin investigating further into course material than we had time to cover.\n\n\nAll course content was either written by Mauricio Buschinelli, Michael Haaf, or explicitly adapted from external resources with attributions made clear. This course content retains the licenses of the original works where relevant, and is otherwise licensed under the Creative Commons Attribution 4.0 International License.\n\nTerms of use\nYou are free to:\n\nShare: copy and redistribute the material in any medium or format\nAdapt: remix, transform, and build upon the material for any purpose, even commercially.\n\nUnder the following terms:\n\nAttribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n\nCreative Commons Attribution 4.0 International License"
  },
  {
    "objectID": "about/this-site/index.html#course-website",
    "href": "about/this-site/index.html#course-website",
    "title": "About this website",
    "section": "2 Course website",
    "text": "2 Course website\nDetails about how this website was built follow.\n\n2.1 Colophon\n\n\n\n\n\nFrom Wikipedia: In publishing, a colophon is a brief statement containing information about the publication of a book… Some web pages also have colophons, which frequently contain (X)HTML, CSS, or usability standards compliance information and links to website validation tests.\n\n\n\nMarkup: Markdown\nFramework: Quarto\nDeployment: GitHub Pages\n\nYou can follow along directly with course updates at the course repository."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "This companion site for the 420-6P3 course includes:\n\n\nLecture slides / documents\nExercises\nReferences & Resources\n\n\nWebsite accessible at john-abbott-college.github.io/6P3-Notes\n\n\nThis course will introduce students to the principles of the Internet of Things (IoT). Students will use Linux and Python to program a Raspberry Pi in order to read data from sensors and control actuators.\nBy the end of the course, students build and deploy an IoT product that is securely connected to the Azure ecosystem in order to collect and analyse telemetry data as well as respond to remote commands.\n\n\n\n\nExperience using Object Oriented Programming to create applications in any language.\nFamiliarity using the Bash shell and basic Linux CLI.\nFamiliarity with Python.\nA Raspberry Pi with various sensors and actuators (see page Hardware List).\nA Microsoft Azure account: create a free Azure for Students account if necessary.\nVS Code configured for Python programming and remote development (see page Dev Setup).\n\n\n\n\nThis webpage is written in Markdown using the Quarto framework. The website is hosted via GitHub Pages\nSource code is open source and available on GitHub.\n\n\nCreate a local copy of these notes:\n\nInstall Quarto for your system\nClone the course GitHub repository.\nPreview the website:\nquarto preview .\n\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. See the Copyright statement on the course webpage."
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Home",
    "section": "",
    "text": "This course will introduce students to the principles of the Internet of Things (IoT). Students will use Linux and Python to program a Raspberry Pi in order to read data from sensors and control actuators.\nBy the end of the course, students build and deploy an IoT product that is securely connected to the Azure ecosystem in order to collect and analyse telemetry data as well as respond to remote commands."
  },
  {
    "objectID": "index.html#requirements",
    "href": "index.html#requirements",
    "title": "Home",
    "section": "",
    "text": "Experience using Object Oriented Programming to create applications in any language.\nFamiliarity using the Bash shell and basic Linux CLI.\nFamiliarity with Python.\nA Raspberry Pi with various sensors and actuators (see page Hardware List).\nA Microsoft Azure account: create a free Azure for Students account if necessary.\nVS Code configured for Python programming and remote development (see page Dev Setup)."
  },
  {
    "objectID": "index.html#source-code",
    "href": "index.html#source-code",
    "title": "Home",
    "section": "",
    "text": "This webpage is written in Markdown using the Quarto framework. The website is hosted via GitHub Pages\nSource code is open source and available on GitHub.\n\n\nCreate a local copy of these notes:\n\nInstall Quarto for your system\nClone the course GitHub repository.\nPreview the website:\nquarto preview .\n\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. See the Copyright statement on the course webpage."
  },
  {
    "objectID": "about/calendar/index.html",
    "href": "about/calendar/index.html",
    "title": "Calendar",
    "section": "",
    "text": "This is the authoritative calendar for content covered in class, and for content you should expect to see covered as we continue through the course.\nYou can compare this calendar with the calendar from the Course Outline to see where this course has deviated from the original outline."
  },
  {
    "objectID": "about/calendar/index.html#deliverables",
    "href": "about/calendar/index.html#deliverables",
    "title": "Calendar",
    "section": "1 Deliverables",
    "text": "1 Deliverables\n\nLab 0: dev env setup and bash review: Due January 31 (Demo: in-class. Code: end of day 11:59pm)\nLab 1: git good, bash better: Due February 10 end of day 11:59pm\nLab 2: Reusing functions in bash: Due February 24 end of day 11:59pm"
  },
  {
    "objectID": "about/calendar/index.html#lectures",
    "href": "about/calendar/index.html#lectures",
    "title": "Calendar",
    "section": "2 Lectures",
    "text": "2 Lectures\n\nJan 20: Introduction to course\nJan 24: Setting up developer environment\nJan 27: Review bash, begin Lab 0\nJan 31: Work on Lab 0\nFeb 3: Begin Lab 1\nFeb 7: (class cancelled, continue lab 1)\nFeb 10: Finish Lab 1\nFeb 14: Start Lab 2\nFeb 17: Class cancelled due to storm\nFeb 21: Continue work on Lab 2\nFeb 24: Begin Lab 3"
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "All course notes",
    "section": "",
    "text": "Default viewTable viewGrid view\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Modified - Oldest\n        \n         \n          Modified - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nCourse hardware\n\n\nList of hardware available for the course as well as their respective specifications and documentation. \n\n\n\nlab-3\n\n\n\n\n\n\nJan 20, 2025\n\n\n3 min\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nDeveloper environment setup\n\n\nInstructions for setting up classroom and personal computers for programming in this course, including: setting up a Debian container on WSL; restoring your WSL container from backup quickly; installing needed dependencies on WSL, Mac/OSX, and Linux; verifying that needed dependencies have been installed. \n\n\n\nlab-0\n\n\nlab-1\n\n\n\n\n\n\nJan 20, 2025\n\n\n6 min\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBash essentials\n\n\nTips for using the bash interactive shell CLI effectively. The core bash commands everyone should know. How to combine commands using pipes and redirects. \n\n\n\nbash\n\n\nlab-0\n\n\nlab-1\n\n\n\n\n\n\nJan 31, 2025\n\n\n8 min\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub basics\n\n\nBasics of cloning a repository hosted on Github and creating branches. Using a personal access token for authentication on GitHub outside of VSCode. Using the pass password manager to store access tokens safely. \n\n\n\ngit\n\n\nlab-1\n\n\n\n\n\n\nFeb 10, 2025\n\n\n5 min\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBash scripting\n\n\nTips for scripting in bash effectively. Managing environment and permissions in bash. The capabilities and limitations of programming in bash. \n\n\n\nbash\n\n\nlab-2\n\n\n\n\n\n\nFeb 17, 2025\n\n\n21 min\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nReterminal setup\n\n\nGuide to setting up reterminal for the first time. \n\n\n\nhardware\n\n\nlab-3\n\n\n\n\n\n\nFeb 24, 2025\n\n\n18 min\n\n\nFeb 28, 2025\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Modified - Oldest\n        \n         \n          Modified - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nSubtitle\n\n\nModified\n\n\n\n\n\n\nJan 20\n\n\nCourse hardware\n\n\nList of hardware available for the course as well as their respective specifications and documentation. \n\n\nFeb 28\n\n\n\n\nJan 20\n\n\nDeveloper environment setup\n\n\nInstructions for setting up classroom and personal computers for programming in this course, including: setting up a Debian container on WSL; restoring your WSL container from backup quickly; installing needed dependencies on WSL, Mac/OSX, and Linux; verifying that needed dependencies have been installed. \n\n\nFeb 28\n\n\n\n\nJan 31\n\n\nBash essentials\n\n\nTips for using the bash interactive shell CLI effectively. The core bash commands everyone should know. How to combine commands using pipes and redirects. \n\n\nFeb 28\n\n\n\n\nFeb 10\n\n\nGitHub basics\n\n\nBasics of cloning a repository hosted on Github and creating branches. Using a personal access token for authentication on GitHub outside of VSCode. Using the pass password manager to store access tokens safely. \n\n\nFeb 28\n\n\n\n\nFeb 17\n\n\nBash scripting\n\n\nTips for scripting in bash effectively. Managing environment and permissions in bash. The capabilities and limitations of programming in bash. \n\n\nFeb 28\n\n\n\n\nFeb 24\n\n\nReterminal setup\n\n\nGuide to setting up reterminal for the first time. \n\n\nFeb 28\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Modified - Oldest\n        \n         \n          Modified - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nCourse hardware\n\n\nList of hardware available for the course as well as their respective specifications and documentation.\n\n\n3 min\n\n\n\nlab-3\n\n\n\n\nJan 20, 2025\n\n\n\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\nDeveloper environment setup\n\n\nInstructions for setting up classroom and personal computers for programming in this course, including: setting up a Debian container on WSL; restoring your WSL container from backup quickly; installing needed dependencies on WSL, Mac/OSX, and Linux; verifying that needed dependencies have been installed.\n\n\n6 min\n\n\n\nlab-0\n\n\nlab-1\n\n\n\n\nJan 20, 2025\n\n\n\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nBash essentials\n\n\nTips for using the bash interactive shell CLI effectively. The core bash commands everyone should know. How to combine commands using pipes and redirects.\n\n\n8 min\n\n\n\nbash\n\n\nlab-0\n\n\nlab-1\n\n\n\n\nJan 31, 2025\n\n\n\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\nGitHub basics\n\n\nBasics of cloning a repository hosted on Github and creating branches. Using a personal access token for authentication on GitHub outside of VSCode. Using the pass password manager to store access tokens safely.\n\n\n5 min\n\n\n\ngit\n\n\nlab-1\n\n\n\n\nFeb 10, 2025\n\n\n\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nBash scripting\n\n\nTips for scripting in bash effectively. Managing environment and permissions in bash. The capabilities and limitations of programming in bash.\n\n\n21 min\n\n\n\nbash\n\n\nlab-2\n\n\n\n\nFeb 17, 2025\n\n\n\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nReterminal setup\n\n\nGuide to setting up reterminal for the first time.\n\n\n18 min\n\n\n\nhardware\n\n\nlab-3\n\n\n\n\nFeb 24, 2025\n\n\n\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n Back to topReuseCC BY-NC 4.0. ©2022-25 Mauricio Buschinelli & Michael Haaf.\n(View License)",
    "crumbs": [
      "All course notes"
    ]
  },
  {
    "objectID": "notes/reterminal-setup/index.html",
    "href": "notes/reterminal-setup/index.html",
    "title": "Reterminal setup",
    "section": "",
    "text": "The reTerminal device. Image source",
    "crumbs": [
      "Reterminal setup"
    ]
  },
  {
    "objectID": "notes/reterminal-setup/index.html#overview",
    "href": "notes/reterminal-setup/index.html#overview",
    "title": "Reterminal setup",
    "section": "1 Overview",
    "text": "1 Overview\nThis page documents the general steps needed to perform an initial set up, or reset, of the reTerminal device that we will be using throughout the class.\nThe general steps are:\n\nInstall necessary dependencies for reimaging a Pi on a host computer\nReimage and configure the reTerminal’s operating system.\nConnect to the reTerminal remotely and ensure the remote connection services are working:\n\nGraphical desktop session using a VNC client.\nCLI session using ssh\n\n\nThese instructions are mostly adapted from the instructions available at (“Getting Started with reTerminal | Seeed Studio Wiki” 2023).",
    "crumbs": [
      "Reterminal setup"
    ]
  },
  {
    "objectID": "notes/reterminal-setup/index.html#prerequisites",
    "href": "notes/reterminal-setup/index.html#prerequisites",
    "title": "Reterminal setup",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nYou can perform this lab on any computer that you are able to run applications with “elevated permissions”.\n\non the Lab computers, you will need to use the “run with elevated permissions” mode at a few steps. This will be explained in class.\non a personal Windows machine, you can follow all of these instructions normally, using “admin” mode when prompted for elevated permissions.\nif you are using a personal macOS or Linux machine, I have not written the instructions with you in mind – you can do this lab, but make sure to adjust the instructions to your OS accordingly\n\n\n2.1 Hardware required\nYou need to prepare the following hardware before getting started with reTerminal:\n\nEthernet cable or Wi-Fi connection\nUSB Type-C cable\nreTerminal kit case, containing\n\nsmall screw driver (black handle)\nreTerminal power adapter\n\n\n\n\n2.2 Software required\nThere are two tools to install for this lab:\n\nRaspberry Pi (RPi) USB Device Boot daemon\nRaspberry Pi Imager\n\nInstructions for installing each follow below.\n\n\n\n\n\n\nNote 1: Elevated Permissions\n\n\n\nWe will sometimes need elevated permissions in order to install or operate software.\n\nOn the Lab Computers, you can achieve elevated permissions by right-clicking on the executable and selecting the option: “Run with elevated access”.\n\nYou will be asked for your college username and password.\n\nClick on the password field to get focus (the program doesn’t focus on the password by default, which is very annoying)\n\nYou will then be asked for a reason for elevating permissions. Copy-paste: “6P3-W25 Raspberry Pi Setup”\n\nOn your personal computers, the options will depend on your OS:\n\nWindows: The same as the Lab Computers, but use “Run as administrator” instead.\nmacOS/Linux: use your terminal environment to run the executable and sudo to elevate your permissions\n\n\n\n\n\n2.2.1 RPi USB Device Boot installation\nThe instructions for installing and using this software vary greatly depending on your host operating system.\nYou can find all instructions in the README of the repository for the software: https://github.com/raspberrypi/usbboot/.\nI’ve adapted those instructions for each possible operating system in the section below.\n\nWindows (recommended)macOS/LinuxWSL\n\n\n\nDownload the repository source code using git clone.\n\nUse your developer environment, i.e. your WSL instance, to do this (not git bash)\n\n(important) Move the cloned usbboot folder to your home directory in the C:\\ drive\n\nPro tip: do this in the terminal using the mv command, e.g. mv /path/to/usbboot /mnt/c/Users/Michael.Haaf/Downloads\n\nin Windows Explorer, locate rpiboot_setup.exe within the usbboot/win32/ directory.\nRun the executable with elevated permissions (see Note 1)\n\nIf the software has already been installed, press Yes to overwrite the existing installation\nBy doing so, we will ensure that the software is the latest version (which will be important).\n\nRaspberry pi drivers will begin to be installed on your computer.\n\nThis process takes a few minutes. Keep the window open and move on to the next steps in the lab.\n\nWhen this process is finished, you should now have the folder C:\\Program Files (x86)\\Raspberry Pi\\ on your computer.\n\n\n\n\n(On macOS / Linux): read the README of the repository and follow those instructions instead.\n\n\n\nNot recommended at this time.\n\n\n\n\n\n2.2.2 Raspberry Pi Imager installation\n\nFollow software from the official Raspberry Pi website.. This software is straightforward to install.\nNOTE: this should already be installed on the Lab computers. Check to see if Raspberry Pi Imager is an application you can open before installing.",
    "crumbs": [
      "Reterminal setup"
    ]
  },
  {
    "objectID": "notes/reterminal-setup/index.html#reimage-the-reterminal",
    "href": "notes/reterminal-setup/index.html#reimage-the-reterminal",
    "title": "Reterminal setup",
    "section": "3 Reimage the reTerminal",
    "text": "3 Reimage the reTerminal\nBelow is a brief overview of the three step process for reimaging the reTerminal:\n\nDisassemble the back cover and flip a switch to have direct access to the eMMc storage\n\nDo not disassemble the entire device! It is only necessary to remove the heatsink.\n\nReimage and configure the OS using the Raspberry Pi Imager software.\nReturn the memory selector switch to the original position and reassemble.\n\n\n3.1 reTerminal Disassembly\n\n\n\n\n\n\nFigure 1: Only remove the heatsink in order to access the memory switch. It is not necessary fully disassemble the reTerminal like they do in the video.\n\n\n\n\nWatch the video in Figure 1 to understand the disassembly process (2 mins).\nFollow Steps 1, 2, & 3 in the reTerminal documentation to remove the heatsink. Flash Raspberry Pi OS/ 64-bit Ubuntu OS or Other OS to eMMC. Use the following hardware from your reTerminal kit:\n\nsmall screw driver (black handle)\nkit case (store the plastic nubs and removed screws in your case. Don’t lose the screws!)\n\n\nAfter the following the above steps, you will have:\n\nremoved the heatsink\ntoggled the eMMc memory switch (see Figure 2).\n\nYour reTerminal is now ready for a firmware flash.\n\n\n\n\n\n\n\nFigure 2: Memory select switch behind the reTerminal’s heatsink in the “down” position.\n\n\n\n\n3.2 New OS image & Configuration\nTo re-image the reTerminal, follow the steps below.\n\n3.2.1 Launch rpiboot\n\nDouble check you have finished the installation\nLaunch the rpiboot executable file with elevated permissions (see Note 1)\n\nOn Windows, this should be C:\\Program Files (x86)\\Raspberry Pi\\rpiboot.exe\nOn a personal macOS/Linux: I think it’s rpiboot.sh in the installation directory, but check the project README to be sure\n\nKeep the rpiboot window open throughout the next steps of this lab.\n\nAfter launching, you should see a terminal window with something like the following dialog appear:\nRPIBOOT: build-date Jan 22 2023 version 20221215-105525 864863bc\nWaiting for BCM2835/6/7/2711...\nThe rpiboot program creates a daemon (a dedicated background process) that will detect when a reTerminal device is connected in flash mode (i.e. the eMMc switch toggled “down” as in Figure 2).\n\n\n3.2.2 Connect the reTerminal to the USB port of your machine.\n\nFind a USB-C to USB 3.0 Cable and plug it into a 3.0 port on your computer.\n\nUSB-C to USB-C is also fine.\n\nPlug the other end of the cable into your reTerminal\n\nNOTE: if the screen of the reTerminal turns on when you plug in the USB cable, you have missed a step in the disassembly process. In this case, stop, unplug the device, and read the previous instructions more carefully.\n\nrpiboot will detect and attach the reTerminal’s internal memory as a storage device.\nAt this stage, you should see some dialog appear in the RPIBOOT program:\n\nSending bootcode4.bin…\nReceived 4 bytes\nsomethingsomethingsomething\nEtc. etc.\nLoading startup.elf file\nWarning: file not interpreted as such-and-such\nFinished\nYour output will not exactly match the example I have provided. Here are some guidelines:\n\nThe program may close on its own, or may not. Either way is fine.\nYou can ignore the “warnings” that appear at the end of the logs.\nYou can ignore the “There is a problem with this drive” Windows notification.\nThe program should NOT repeatedly loop at Sending bootcode4.bin...\n\nif this is the case, and no other messages appear, try the previous steps again, make sure you pay attention to details.\n\n\nBasically, unless the program is stuck in a loop, you should continue to the next step.\n\n\n3.2.3 Run Rasperry Pi (RPi) Imager\n\nRun the program on your desktop with elevated permissions (see Note 1)\nBefore making any selections, press Control+Shift+X to open the “OS Customizations” Advanced Options menu.\nMake the following customizations (you will need to click through all 3 tabs at the top).\n\nSet a unique hostname (suggestion: your github username)\nEnable SSH with password authentication.\nSet a unique username and password.\n\nDo not use the defaults or forget these. You will need to reimage your reTerminal if you do.\n\nConfigure the wireless LAN for the lab network:\n\nSSID: P326-hotspot\n\nNOTE: there is no whitespace. Take care your SSID matches exactly.\n\nPassword: 6P3-W25-pallet-overcast\n\nNOTE: take care your password matches exactly\n\nWireless LAN country: CA\n\nSet locale settings: America/Montreal\nDisable telemetry.\nEnable “eject media” and “play sound when finished”.\nTake note of your hostname, username, and password (see Moodle for place to enter this information)\n\nYou will be responsible for maintaining your system.\nIf you get locked out, you may have to re-image the system.\n\nPress “SAVE” when finished.\n\nOnce you’ve finished making the above customizations, there are three main configuration choices to make:\n\nRaspberry Pi Device: Raspberry Pi 4\nOperating System: Raspberry Pi OS 64-bit (Recommended)\nStorage: RPi-MSD-0001 (31.3GB). DO NOT SELECT ANY OTHER STORAGE DEVICE.\n\nIf this storage device does not appear, you need to re-do the rpiboot steps\n\n\nOnce Raspberry Pi Images starts, writing the image to the reTerminal’s memory can take 10-15 minutes.\n\nDo not disconnect the reTerminal during flashing!\n\n\n\n\n\n3.3 Reassembly\n\nOnce the writing and verification process is completed, disconnect the USB-C cable from the reTerminal.\nReturn the memory select switch to the original position. (Do you know why? If not, Reread the part about why we toggled it down in the first place!)\nDon’t re-assemble the heatsink+terminal cover yet – we have a few more steps to take first.\nPlug the raspberry pi into the wall using the Pi Power Supply cable in your reTerminal kit. You may need an extension cord/power bar– you can find one at the front of the class.",
    "crumbs": [
      "Reterminal setup"
    ]
  },
  {
    "objectID": "notes/reterminal-setup/index.html#first-boot",
    "href": "notes/reterminal-setup/index.html#first-boot",
    "title": "Reterminal setup",
    "section": "4 First Boot",
    "text": "4 First Boot\nYour reTerminal has been re-imaged! Make sure you have completed the reassembly steps, particularly that you have toggled the memory select switch back up to normal boot mode.\nAt this point, we are now going to start running commands directly on the reTerminal itself. Follow the steps below:\n\nPlug your reTerminal into the wall using the power supply. There are power bars in the lab that you can use if you need more outlets.\n\nIn general, the reTerminal is powered using the provided power supply in your lab kit.\n\nPlug your reTerminal into the lab monitor using the provided microHDMI to HDMI converter\nPlug your reTerminal into the ethernet using the lab computer ethernet.\nPlug the lab keyboard and mouse into your reterminal USB.\n\nOn first boot, your reTerminal screen will not turn on – this is why we need the microHDMI connection to the external monitor.\nThe first task we need to take care of is fixing the reTerminal screen display drivers.\n\n4.1 Display driver fix\nOnce your are logged into the reTerminal and you can see the display on the lab monitor, follow the steps below:\n\nRead and follow the steps outlined here: “Install reTerminal drivers after flashing new Raspberry Pi OS/ Ubuntu OS or Other OS”, up to and including sudo reboot.\n\nNOTE: recall that you have installed a 64-bit OS on your reTerminal. Do not follow any 32-bit OS steps in the above instructions.\n\nIf the above steps have been completed successfully, your device should reboot and BOTH the raspberry pi screen AND the HDMI connection should work (this takes several seconds, give it a minute before you panic).\n\nMake sure your Pi is connected to the wall power supply, NOT to your computer (the pi screen needs more power than your lab computer can provide).\n\n\n\n\n4.2 Update & Upgrade\nA good first step for any OS installation is to ensure all system packages are at the latest version.\nFollow the three steos in the official guide for the reTerminal FAQ Wiki: How to upgrade Raspberry Pi OS and the installed packages - For any steps that ask you to make a choice, just pick the defaults.",
    "crumbs": [
      "Reterminal setup"
    ]
  },
  {
    "objectID": "notes/reterminal-setup/index.html#set-up-remote-connections",
    "href": "notes/reterminal-setup/index.html#set-up-remote-connections",
    "title": "Reterminal setup",
    "section": "5 Set up Remote connections",
    "text": "5 Set up Remote connections\nGoing forward, we want to be able to use the reTerminal without having to plug it into an external monitor.\nFixing the device screen was one step – however, we would also like to be able to use the reTerminal without relying on the small touchscreen either.\nWe are going to rely on remote connections to the reTerminal in general in this class – that is, connecting to the reTerminal using an IP Address.\nBecause the lab network has firewalls, however, we cannot do so directly using the lab ethernet or the campus WIFI.\nTo fix this problem, we are going to use a remote networking tool called Tailscale. Follow the steps below:\n\n5.1 Set up Tailscale\nFirst, create an account on Tailscale. You have the following choices for authentication: - (Recommended) Your GitHub account - Your school email address\nIf you’re curious to know more about Tailscale before you sign up, please ask me! You can also read about it here: - https://tailscale.com/why-tailscale - https://tailscale.com/blog/how-tailscale-works\nIn the big picture: Tailscale will allow us to establish direct remote connections between our raspberry Pi and our developer environments.\nTo be clear, Tailscale is free, you will not need any of the paid features.\nAfter you have made an account, you will need to set it up on your pi and your developer environments, see instructions below.\n\n5.1.1 On the raspberry pi\nFollow these instructions\nYou can do the “Install with one command” step, OR follow the manual steps if you prefer.\n\n\n5.1.2 On your lab computer\n\nInstall on your WSL by Following these instructions\n\nYou can do the “Install with one command” step, OR follow the manual steps if you prefer.\nNOTE: you will probably need to also run the following command on your WSL:\n\nsudo apt install curl\n\n\nALSO install on the main Windows machine by following these instructions\n\nYou may need to use elevated permissions for this, see Note 1\n\n\n\n\n5.1.3 On your personal computer\nDepending on your operating system: - Windows: - Install on your WSL by Following these instructions - You can do the “Install with one command” step, OR follow the manual steps if you prefer. - NOTE: you will probably need to also run the following command on your WSL: - sudo apt install curl - macOS: Follow these instructions - Linux: Follow these instructions\nYou can do the “Install with one command” step, OR follow the manual steps if you prefer.\n\n\n5.1.4 Verify your tailscale setup\nOn either your lab/personal developer environment, OR your raspberry pi, run the command:\ntailscale status\nYou should see the IP address for both your reTerminal AND your lab/personal developer environment. Take note of these IP addresses before moving on to the next steps.\n\n\n\n5.2 Set up VNC\nIn this section you will connect to the graphical desktop environment remotely using a VNC session. This will allow you to control the raspberry pi from your lab computer over the graphical shell of the lab computer, in addition to SSH.\n\nOnce connected to the provided power cable, the reTerminal will boot and automatically login into the graphical desktop environment as the default user.\nThe reTerminal has a touch screen which you are welcome to use for the next steps. However, I recommend plugging in your lab keyboard and/or mouse for these next few steps. Let me know if you need a keyboard/mouse.\nEnable the VNC client in the Raspberry Pi Configuration menu.\n\nClick on the Raspberry Pi icon (top right).\nSelect Preferences &gt; Raspberry Pi Configuration.\nOpen the Interfaces tab.\nEnable the VNC server (disabled by default).\n\nOpen a terminal on your Raspberry Pi. You want to double check your IP address.\nTake note of your Raspberry Pi’s local IP address.\nAt your lab computer, start the VNC Viewer client (RealVNC). You can run this program without elevated access.\nConnect to your Raspberry Pi using VNC Viewer in your lab computer.\nEnter the hostname you assigned to your Raspberry Pi in Part 1, step 5 or the IP address you noted in step 5.\n\nUse the username and password you configured in Part 1, step 5.\n\n\n\n\n5.3 Set up SSH\nThe SSH server inside your Raspberry Pi should already be enabled by default (from Part 1, step 5).\n\nTo double check that the ssh server is enabled on your Pi: follow the official instructions on Setting up the SSH Server on the Raspberry Pi.\n\n\n5.3.1 Connecting over CLI\nYou can establish an SSH connection to the reTerminal from your developer environment. If your connection is successful you should see the a similar prompt:\nuser-name@hostname:~ $\nwhere hostname and user-name correspond to the choices you made during your imaging of the pi.\n\nFollow the official Raspberry Pi instructions (NOTE: Linux instructions apply to WSL!) Secure Shell from Linux or Mac OS\n\nFor Lab 3, I ask you to obtain the reTerminal’s MAC address.\nYou can do so running ifconfig command in an ssh session, and checking the properties of the wireless network card (wlan0):\n\nRun the command ifconfig or the command ip address\nLook for the wireless network adapter wlan0:\nThe MAC address will be listed there.I\n\nStyle points: use grep and pipe to grab the MAC address directly to your clipboard\n\n\n\n\n5.3.2 Connecting over VSCode\nYou can use VS Code in your lab workstation to create a development environment inside the Raspberry Pi which will be controlled from the lab workstation.\nIf you would like to know more about how this extension works, visit Remote Development using SSH.\nBelow is a 5min video that illustrates how the Remote - SSH extension works:\nVS Code Remote Development using SSH to a Raspberry Pi\n\nIn your lab workstation, ensure you have installed the following VS Code extensions:\n\nRemote - SSH, by Microsoft.\nPython extension, by Microsoft.\n\nConnect your lab workstation to your Raspberry Pi by following the Remote - SSH extension’s official instructions: Getting started. Once VS Code is connected to the reTerminal, you are now in a new development environment inside the reTerminal. Complete the following tasks:\nInstall the VS Code Python extension (this time inside the reTerminal, not in your lab workstation like in step 1).\n\nIf necessary, follow the guide: Getting Started with Python in VS Code\n\nOn the Raspberry Pi, open the folder lab1 in the home directory of the reTerminal (created in Part 3, step 4).\nCreate a new file named lab-script.py inside the folder lab1 and include the code:\n\nprint(‘Hello from inside the pi!’)\n\nExecute your code from within VS Code using the play button.",
    "crumbs": [
      "Reterminal setup"
    ]
  },
  {
    "objectID": "notes/course-hardware/index.html",
    "href": "notes/course-hardware/index.html",
    "title": "Course hardware",
    "section": "",
    "text": "Image source",
    "crumbs": [
      "Course hardware"
    ]
  },
  {
    "objectID": "notes/course-hardware/index.html#reterminal",
    "href": "notes/course-hardware/index.html#reterminal",
    "title": "Course hardware",
    "section": "1 reTerminal",
    "text": "1 reTerminal\nThe reTerminal is a development board based on the Raspberry Pi Compute Module 4 (CM4) manufactured by Seeed Studio.\n\nSee reTerminal Wiki page for the complete specs and documentation\n\nMost of the information from the following sections was scraped from (“Getting Started with reTerminal | Seeed Studio Wiki” 2023)\n\n1.1 Features\n\nIntegrated modular design with high stability and expandability\nPowered by Raspberry Pi Computer Module 4 with 4GB RAM & 32GB eMMC\n5-Inch IPS capacitive multi-touch screen at 1280 x 720 and 293 PPI\nWireless connectivity with dual-band 2.4GHz/5GHz Wi-Fi and Bluetooth 5.0 BLE\nHigh-speed expansion interface and rich I/O for more expandability\nCryptographic co-processor with secure hardware-based key storage\nBuilt-in modules such as accelerometer, light sensor and RTC\nGigabit Ethernet Port and Dual USB 2.0 Type-A ports\n40-Pin header for IoT applications\n\n\n\n1.2 Specifications\nSee Specifications on the reTerminal wiki webpage.\n\n\n1.3 Hardware Overview\n\n1.3.1 Chassis\n\n\n\npir\n\n\n\n\n1.3.2 Motherboard\n\n\n\npir\n\n\n\n\n1.3.3 Block Diagram​\n\n\n\npir\n\n\n\n\n1.3.4 Pinout Diagram​\n\n\n\nPlease carefully pay attention to the orientation of the reTerminal in the above diagram. The LCD and the onboard buttons are on the right side whereas the back of reTerminal is on the left side. Also the whole device is flipped upside down.\n\n\n\n\n\n1.4 Power Supply\n\n\n\n\n\nRPI USB-C POWER SUPPLY BLACK US\n\n\nThe reTerminal requires a power supply that can provide a minimum of 3 Amps. The official Raspberry Pi USB-C Power Supply in included in the kit.",
    "crumbs": [
      "Course hardware"
    ]
  },
  {
    "objectID": "notes/course-hardware/index.html#compute-module-4",
    "href": "notes/course-hardware/index.html#compute-module-4",
    "title": "Course hardware",
    "section": "2 Compute Module 4",
    "text": "2 Compute Module 4\n\n\n\n\n\nRaspberry PI CM 4\n\n\nThe Compute Module 4 (CM4) made by the Raspberry Pi Foundation is powering the reTerminal.\nNotable features:\n\nProcessor: Broadcom BCM2711 quad-core Cortex-A72 (ARM v8) 64-bit SoC @ 1.5GHz\n\n\nSee CM4 datasheet for details.\n\nSee Difference Between ARM64, ARMel, and ARMhf for more info on the different ARM architectures.\n\n2.1 Grove Base Hat for Raspberry Pi\n\n\n\n\n\nGrove Base Hat for GPIO connections\n\n\nIn a typical Raspberry Pi, sensors would be connected via the 40-pin GPIO.\nTo facilitate connections of the Grove sensors, this “Hat” (term for an add-on board of the Raspberry Pi) includes the following types of connection:\n\n6 Digital\n4 Analog\n3 I2C\n1 PWM\n1 UART\n\n\nSee Grove base hat Wiki for details.",
    "crumbs": [
      "Course hardware"
    ]
  },
  {
    "objectID": "notes/course-hardware/index.html#sensors",
    "href": "notes/course-hardware/index.html#sensors",
    "title": "Course hardware",
    "section": "3 Sensors",
    "text": "3 Sensors\n\n3.1 AHT20 I2C Temperature & Humidity\n\n\n\n\n\nAHT20 I2C temperature/humidity sensor\n\n\nSee AHT20 I2C Industrial Grade Temperature & Humidity Sensor wiki for details.\n\nTemperature measurement range -40 ~ 85°C, Humidity measurement range 0 ~ 100% RH.\nDigital output, Grove I2C interface.\n\n\n\n3.2 AHT20 Libraries\nThe main module for this sensor is provided by Seeed in this Github repository and can be installed with the grove.py library.\nFollow official Step by step installation for python 3 (see below). Don’t use the one-click installation or it will install to the wrong location\ngit clone [https://github.com/Seeed-Studio/grove.py](https://github.com/Seeed-Studio/grove.py)\ncd grove.py\nsudo pip3 install .\nAlternatively, it’s also possible to use Adafruit’s adafruit-circuitpython-ahtx0 library to communicate with the sensor (see library’s Pypi page). However, to instantiate the provided sensor class, you will need to pass it an I2C bus instance. To instantiate an I2C bus instance, install and use the adafruit-extended-bus library (see Pypi page).",
    "crumbs": [
      "Course hardware"
    ]
  },
  {
    "objectID": "notes/course-hardware/index.html#actuators-motors",
    "href": "notes/course-hardware/index.html#actuators-motors",
    "title": "Course hardware",
    "section": "4 Actuators & Motors",
    "text": "4 Actuators & Motors\n\n4.1 LED Socket\n\n\n\n\n\nLED\n\n\nLED in a removable socket and potentiometer for power adjustment. LED can be swapped with different colors.\nSee LED wiki page for details.\n\n\n4.2 Cooling Fan\n\n\n\n\n\nCooling Fan\n\n\n5V Cooling Fan 40mm x 10mm with 2-pin JST connector.\n\nSee product page here.\n\n\n\n4.3 Relay\n\n\n\n\n\nRelay switch\n\n\nA digital switch. Controls the on/off flow of electricity with a small digital signal.\n\nOperate voltage: 3.3V-5V\nInput current: 100mA\nRated load: 5A@250VAC 5A@30VDC\n\nSee relay wiki page for details.",
    "crumbs": [
      "Course hardware"
    ]
  },
  {
    "objectID": "notes/course-hardware/index.html#cabling",
    "href": "notes/course-hardware/index.html#cabling",
    "title": "Course hardware",
    "section": "5 Cabling",
    "text": "5 Cabling\nThe following cables are included in the base kit:\n\nGrove Universal 4 Pin Buckled 5cm Cable.\nGrove Universal 4 Pin Buckled 20cm Cable.\nGrove 4 pin Female Jumper to Grove 4 pin Cable\nGrove 4 pin Male Jumper to Grove 4 pin Cable\n40-pin flat ribbon cable 20cm (female-female).\n2-pin JST SM Plug, one end open.",
    "crumbs": [
      "Course hardware"
    ]
  },
  {
    "objectID": "notes/github-basics/index.html#overview",
    "href": "notes/github-basics/index.html#overview",
    "title": "GitHub basics",
    "section": "1 Overview",
    "text": "1 Overview\nThese notes cover the basics for using GitHub in this class.",
    "crumbs": [
      "GitHub basics"
    ]
  },
  {
    "objectID": "notes/github-basics/index.html#branch-management",
    "href": "notes/github-basics/index.html#branch-management",
    "title": "GitHub basics",
    "section": "2 Branch management",
    "text": "2 Branch management\nAlmost all of our lab and assignment work will take place on branches.\n\n2.1 Creating a branch using the GitHub website\nYou can add branches to your repository directly by clicking the “Branches” icon, and then “New Branch” on the subsequent window (screenshots below).\nYou’ll need the following information:\n\nNew branch name: the lab name (e.g. lab-0).\nSource: the instructions branch from your own repository\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: The user interface for creating branches on GitHub.\n\n\n\n\n\n2.2 Creating a branch using VSCode\nYou can create branches within your project using VSCode:\n\n\n\n\n\n\nFigure 2: Clicking on the branch button (bottom left) launches a dialog which allows for a few branch operations: you can create a new branch, switch to a local branch, switch/pull a remote branch, etc.\n\n\n\n\n\n2.3 Creating a branch using the command line\n# make sure you are on the `instructions` branch before proceeding\ngit status\n# the switch command switches branches, -c flag stands for \"create\"\ngit switch -c lab-0\n# upload your branch to the remote repository\ngit push -u origin\n# ensure your new lab-0 branch is up to date with new remote lab-0 branch\ngit status",
    "crumbs": [
      "GitHub basics"
    ]
  },
  {
    "objectID": "notes/github-basics/index.html#authentication",
    "href": "notes/github-basics/index.html#authentication",
    "title": "GitHub basics",
    "section": "3 Authentication",
    "text": "3 Authentication\nMany git operations require authentication to get permission. Some examples:\n\nPushing to a repository\nPulling from a private repository\nUsing GitHub CLI\n\nSince July 2021, GitHub no longer accepts account passwords to authenticate git operations. You have probably run into this error many times when trying to push changes or clone your private repositories on a new machine.\nThe only reason VSCode works out of the box is because VSCode and GitHub are integrated by default, both being owned by Microsoft.\nThe following sections gives us more flexible and useful ways to authenticate git commands with GitHub.\n\n3.1 Creating a personal access token\nRead “Managing your personal access tokens” on Github, and create a classic (not fine-grained) personal access token.\nAt the very least, select the repo scope – this will give your token the ability to authenticate using git on the CLI. You can select all other scopes as well if you like.\nOnce you’re finished, you’ll see your token is a string of the following form:\nghp_&lt;long string of letters and numbers&gt;\nKeep this window open – the string of characters will disappear as soon as you refresh the page.\nWe need to configure a secure storage location for this string. For this, we will use the tool pass.\n\n\n3.2 Using a password manager to store your token\nSecrets like personal access tokens need to be readily accessible to be useful – but they also should be secret, so that others cannot easily impersonate you using the token.\nA common method for managing secrets is to use a password manager. In our course we use pass to securely manage our personal access tokens on our developer environment.\n\n3.2.1 Install pass dependencies\nFirst, ensure pass and some useful related dependencies are installed:\n# On WSL / Linux\nsudo apt install pass pass-extension-otp zbar-tools\n\n# On macOS\nbrew install pass pass-otp zbar\n\n\n3.2.2 Set up gpg\npass works by using asymmetric key encryption to store secrets. That means: you posess the private key that can decrypt secrets, and you make the public key available which can encrypt secrets.\nThis scheme is not only useful for private communication (something similar is used by apps like Signal and Telegram), but also for storing any secrets – for us, we will store our github token as a secret.\nTo get started, you’ll need to generated a gpg key-pair in order to use pass.\n\n\n\n\n\n\nNote\n\n\n\nThe GitHub instructions mention using git bash – ignore them, you have a developer environment to use instead.\nIn general, when I link to external instructions, you will need to pay attention to what parts of them may be different in our class. This is a good skill in general for making effective use of resources posted online when learning a new skill.\n\n\nFollow the instructions below:\n\nCreate the gpg key-pair following the instructions on GitHub: Generating a new GPG key\nrun gpg --full-generate-key to get started.\nRecommended: You can accept the default key type (RSA)\nRecommended: Choose 4096 bits for the keysize.\nRecommended: You can accept the default “does not expire” option.\nEnter user ID information. This information should match what you have provided to GitHub already (username/email address)\nYou have to choose a password for GPG keys. Choose something strong that you can remember.\nAdd the public key to your GitHub account following the instructions: Adding a GPG Key to your GitHub account.\n\nThe name of the key on GitHub does not matter (Personal GPG Key is fine)\nThe command: gpg --armor --export prints your key to the console, you can copy/paste this output for GitHub\nEven better: use a pipe to clip.exe to put the key in your clipboard automatically with gpg --armor --export | clip.exe\n\non macOS: use pbcopy instead of clip.exe\non Linux: use xclip or wl-copy instead of clip.exe\n\n\n\n3.2.3 Store personal access token in pass\nOnce you’ve created the gpg key-pair, we can now set up pass:\npass init &lt;the-email-you-used-for-gpg-key&gt;\nFinally, copy the token string from GitHub to your clipboard. Then, open your developer terminal:\n$ pass insert github/token\nEnter password for github/token: # paste your token here, then press enter\nOnce you’ve done this, you should be able to access your token using pass github/token, or pass github/token | clip.exe to place it on your clipboard directly.\n\n\n\n3.3 Troubleshooting\nSome common errors that arise with using gpg:\n\n3.3.1 No secret key\nThis error looks like:\n\n\nbash\n\n$ pass github/token\ngpg: decryption failed: No secret key\n\nTry the following:\n\n3.3.1.1 Double check the password store setup\nConfirm that your password store is encrypted with the gpg key you expect:\n\n\nbash\n\n# This command prints out your gpg key information\n$ gpg -k \n\n# This command shows the gpg key used to encrypt your password-store\n$ cat ~/.password-store/.gpg-id\n\n# The id and/or email address should match for both!\n\n\n\n3.3.1.2 Restart gpg daemon\n\n\nbash\n\n$ gpgconf --kill gpg-agent\n\nIf that doesn’t work, try restarting your WSL instance. In powershell:\n\n\nPowershell\n\nPS &gt; wsl --shutdown &lt;distro-name&gt;\n\nAfter the shutdown attempt, retry using pass in the WSL again.",
    "crumbs": [
      "GitHub basics"
    ]
  }
]